<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>pytorch_learning</title>
      <link href="/2023/01/05/pytorch-learning/"/>
      <url>/2023/01/05/pytorch-learning/</url>
      
        <content type="html"><![CDATA[<p>本文参考：<a href="https://www.pytorchmaster.com/">https://www.pytorchmaster.com/</a></p><h3 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h3><h4 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h4><p>基本上趋同于numpy.array，但是<strong>不支持str</strong>!!!   包括：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">torch.float64(torch.double),</span><br><span class="line">torch.float32(torch.<span class="built_in">float</span>),</span><br><span class="line">torch.float16,</span><br><span class="line">torch.int64(torch.long),</span><br><span class="line">torch.int32(torch.<span class="built_in">int</span>),</span><br><span class="line">torch.int16,</span><br><span class="line">torch.int8,</span><br><span class="line">torch.uint8,</span><br><span class="line">torch.<span class="built_in">bool</span></span><br></pre></td></tr></table></figure><p>一般神经网络都是用<code>torch.float32</code>类型</p><p>几种构造方式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自动推断</span></span><br><span class="line">a = torch.tensor(<span class="number">2.0</span>)</span><br><span class="line"><span class="built_in">print</span>(a,a.dtype)</span><br><span class="line"><span class="comment"># tensor(2.) torch.float32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定数据类型</span></span><br><span class="line">b = torch.tensor(<span class="number">2.0</span>, dtype=torch.double)</span><br><span class="line"><span class="built_in">print</span>(b,b.dtype)</span><br><span class="line"><span class="comment"># tensor(2.,dtype=torch.float64) torch.float64</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#使用特定构造函数 &amp; numpt转tensor</span></span><br><span class="line">c = torch.IntTensor(<span class="number">1</span>)</span><br><span class="line">d = torch.Tensor(np.array(<span class="number">2.0</span>))  <span class="comment">#等价于torch.FloatTensor</span></span><br><span class="line">e = torch.BoolTensor(np.array([<span class="number">1</span>,<span class="number">0</span>,<span class="number">2</span>,<span class="number">0</span>]))</span><br><span class="line"><span class="built_in">print</span>(c,c.dtype)</span><br><span class="line"><span class="built_in">print</span>(d,d.dtype)</span><br><span class="line"><span class="built_in">print</span>(e,e.dtype)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([5], dtype=torch.int32) torch.int32</span></span><br><span class="line"><span class="string">tensor(2.) torch.float32</span></span><br><span class="line"><span class="string">tensor([ True, False,  True, False]) torch.bool</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 不同类型转换</span></span><br><span class="line">i = torch.tensor(<span class="number">1</span>); <span class="built_in">print</span>(i,i.dtype)</span><br><span class="line">x = i.<span class="built_in">float</span>(); <span class="built_in">print</span>(x,x.dtype) <span class="comment">#调用 float方法转换成浮点类型</span></span><br><span class="line">y = i.<span class="built_in">type</span>(torch.<span class="built_in">float</span>); <span class="built_in">print</span>(y,y.dtype) <span class="comment">#使用type函数转换成浮点类型</span></span><br><span class="line">z = i.type_as(x);<span class="built_in">print</span>(z,z.dtype) <span class="comment">#使用type_as方法转换成某个Tensor相同类型</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor(1) torch.int64</span></span><br><span class="line"><span class="string">tensor(1.) torch.float32</span></span><br><span class="line"><span class="string">tensor(1.) torch.float32</span></span><br><span class="line"><span class="string">tensor(1.) torch.float32</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h4 id="张量的维度"><a href="#张量的维度" class="headerlink" title="张量的维度"></a>张量的维度</h4><p>不同类型数据会是不同的维度，<strong>有几层中括号就是多少维张量</strong></p><hr><p>标量为0维张量，向量为1维张量，矩阵为2维张量，彩色图像有rgb三个通道为3维张量，视频还有时间维表示为4维张量。</p><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scalar = torch.tensor(<span class="literal">True</span>) <span class="comment"># 0维</span></span><br><span class="line">vector = torch.tensor([<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>,<span class="number">4.0</span>]) <span class="comment">#向量，1维张量</span></span><br><span class="line">matrix = torch.tensor([[<span class="number">1.0</span>,<span class="number">2.0</span>],[<span class="number">3.0</span>,<span class="number">4.0</span>]]) <span class="comment">#矩阵, 2维张量</span></span><br><span class="line">tensor3 = torch.tensor([[[<span class="number">1.0</span>,<span class="number">2.0</span>],[<span class="number">3.0</span>,<span class="number">4.0</span>]],[[<span class="number">5.0</span>,<span class="number">6.0</span>],[<span class="number">7.0</span>,<span class="number">8.0</span>]]])  <span class="comment"># 3维张量</span></span><br><span class="line">tensor4 = torch.tensor([[[[<span class="number">1.0</span>,<span class="number">1.0</span>],[<span class="number">2.0</span>,<span class="number">2.0</span>]],[[<span class="number">3.0</span>,<span class="number">3.0</span>],[<span class="number">4.0</span>,<span class="number">4.0</span>]]],</span><br><span class="line">                        [[[<span class="number">5.0</span>,<span class="number">5.0</span>],[<span class="number">6.0</span>,<span class="number">6.0</span>]],[[<span class="number">7.0</span>,<span class="number">7.0</span>],[<span class="number">8.0</span>,<span class="number">8.0</span>]]]])  <span class="comment"># 4维张量</span></span><br></pre></td></tr></table></figure><h4 id="张量的尺寸"><a href="#张量的尺寸" class="headerlink" title="张量的尺寸"></a>张量的尺寸</h4><ul><li>使用<code>shape</code>属性或者<code>size()</code>方法查看张量在每一维的长度</li><li>使用<code>view()</code>方法改变张量的尺寸,view()和numpy中的reshape很像，所以<strong>view()失败可以直接使用reshape</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 有些操作会让张量存储结构扭曲，直接使用view会失败，可以用reshape方法</span></span><br><span class="line">matrix26 = torch.arange(<span class="number">0</span>,<span class="number">12</span>).view(<span class="number">2</span>,<span class="number">6</span>)</span><br><span class="line"><span class="built_in">print</span>(matrix26)       <span class="comment"># tensor([[ 0,  1,  2,  3,  4,  5],</span></span><br><span class="line">          <span class="comment">#[ 6,  7,  8,  9, 10, 11]])</span></span><br><span class="line"><span class="built_in">print</span>(matrix26.shape) <span class="comment"># torch.Size([2, 6])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 转置操作让张量存储结构扭曲</span></span><br><span class="line">matrix62 = matrix26.t()</span><br><span class="line"><span class="built_in">print</span>(matrix62.is_contiguous()) <span class="comment"># False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 直接使用view方法会失败，可以使用reshape方法</span></span><br><span class="line"><span class="comment">#matrix34 = matrix62.view(3,4) #error!</span></span><br><span class="line">matrix34 = matrix62.reshape(<span class="number">3</span>,<span class="number">4</span>) <span class="comment">#等价于matrix34 = matrix62.contiguous().view(3,4)</span></span><br><span class="line"><span class="built_in">print</span>(matrix34) </span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[ 0,  6,  1,  7],</span></span><br><span class="line"><span class="string">        [ 2,  8,  3,  9],</span></span><br><span class="line"><span class="string">        [ 4, 10,  5, 11]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><strong>is_contiguous()：Tensor底层一维数组元素的存储顺序与Tensor按行优先一维展开的元素顺序是否一致</strong></p><p>行有限列有限博客：<a href="https://zhuanlan.zhihu.com/p/64551412">https://zhuanlan.zhihu.com/p/64551412</a></p><h4 id="张量和numpy数组"><a href="#张量和numpy数组" class="headerlink" title="张量和numpy数组"></a>张量和numpy数组</h4><p>numpy –&gt; tensor</p><ul><li>用numpy方法从Tensor得到numpy数组</li><li>用torch.from_numpy从numpy数组得到Tensor</li></ul><p>这两种方法关联的tensor和numpy数组是共享数据内存的，改变一个也会改变另一个。当然需要的话可以通过张量的<code>clone</code>方法拷贝张量中断这种关联。</p><p>此外可以使用<code>item</code>方法从标量张量得到对应的Python数值</p><p>​使用<code>tolist</code>方法从张量得到对应的Python数值列表</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ndarray-&gt;tensor</span></span><br><span class="line">arr = np.zeros(<span class="number">3</span>)</span><br><span class="line">tensor = torch.from_numpy(arr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensor-&gt;ndarray</span></span><br><span class="line">tensor = torch.zeros(<span class="number">3</span>)</span><br><span class="line">arr = tensor.numpy()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以用clone() 方法拷贝张量，中断这种关联</span></span><br><span class="line">tensor = torch.zeros(<span class="number">3</span>)</span><br><span class="line">arr = tensor.clone().numpy() <span class="comment"># 也可以使用tensor.data.numpy()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># item方法和tolist方法可以将张量转换成Python数值和数值列表</span></span><br><span class="line">scalar = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line">s = scalar.item()</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(s),<span class="string">&#x27; &#x27;</span>,s)</span><br><span class="line"><span class="comment"># &lt;class &#x27;float&#x27;&gt; 1.0</span></span><br><span class="line"></span><br><span class="line">tensor = torch.rand(<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">t = tensor.tolist()</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(t),<span class="string">&#x27; &#x27;</span>,t)</span><br><span class="line">&lt;<span class="keyword">class</span> <span class="string">&#x27;list&#x27;</span>&gt; [[<span class="number">0.8211846351623535</span>, <span class="number">0.20020723342895508</span>], [<span class="number">0.011571824550628662</span>, <span class="number">0.2906131148338318</span>]]</span><br></pre></td></tr></table></figure><h3 id="autograd自动微分"><a href="#autograd自动微分" class="headerlink" title="autograd自动微分"></a>autograd自动微分</h3><p>神经网络通常依靠反向传播求梯度更新网络参数，pytorch通过反向传播backward方法实现梯度计算，可以调用torch.autograd.grad函数来实现梯度计算，这就是Pytorch的自动微分机制</p><h4 id="backward求导数"><a href="#backward求导数" class="headerlink" title="backward求导数"></a>backward求导数</h4><p>backward 方法通常在一个标量张量上调用，该方法求得的梯度将存在对应自变量张量的grad属性下。</p><p>如果调用的张量非标量，则要传入一个和它同形状 的gradient参数张量。</p><p>相当于用该gradient参数张量与调用张量作向量点乘，得到的标量结果再反向传播。</p><ol><li>标量的反向传播</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># f(x) = a*x**2 + b*x + c的导数</span></span><br><span class="line">x = torch.tensor(<span class="number">0.0</span>,requires_grad = <span class="literal">True</span>) <span class="comment"># x需要被求导</span></span><br><span class="line">a = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line">b = torch.tensor(-<span class="number">2.0</span>)</span><br><span class="line">c = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line">y = a*torch.<span class="built_in">pow</span>(x,<span class="number">2</span>) + b*x + c </span><br><span class="line"></span><br><span class="line">y.backward()</span><br><span class="line">dy_dx = x.grad</span><br><span class="line"><span class="built_in">print</span>(dy_dx) <span class="comment"># tensor(-2.)</span></span><br></pre></td></tr></table></figure><ol start="2"><li>非标量的反向传播</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"></span><br><span class="line"><span class="comment"># f(x) = a*x**2 + b*x + c</span></span><br><span class="line">x = torch.tensor([[<span class="number">0.0</span>,<span class="number">0.0</span>],[<span class="number">1.0</span>,<span class="number">2.0</span>]],requires_grad = <span class="literal">True</span>) <span class="comment"># x需要被求导</span></span><br><span class="line">a = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line">b = torch.tensor(-<span class="number">2.0</span>)</span><br><span class="line">c = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line">y = a*torch.<span class="built_in">pow</span>(x,<span class="number">2</span>) + b*x + c </span><br><span class="line"></span><br><span class="line">gradient = torch.tensor([[<span class="number">1.0</span>,<span class="number">1.0</span>],[<span class="number">1.0</span>,<span class="number">1.0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x:\n&quot;</span>,x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y:\n&quot;</span>,y)</span><br><span class="line">y.backward(gradient = gradient)</span><br><span class="line">x_grad = x.grad</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x_grad:\n&quot;</span>,x_grad)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">x:</span></span><br><span class="line"><span class="string"> tensor([[0., 0.],</span></span><br><span class="line"><span class="string">        [1., 2.]], requires_grad=True)</span></span><br><span class="line"><span class="string">y:</span></span><br><span class="line"><span class="string"> tensor([[1., 1.],</span></span><br><span class="line"><span class="string">        [0., 1.]], grad_fn=&lt;AddBackward0&gt;)</span></span><br><span class="line"><span class="string">x_grad:</span></span><br><span class="line"><span class="string"> tensor([[-2., -2.],</span></span><br><span class="line"><span class="string">        [ 0.,  2.]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><ol start="3"><li>非标量的反向传播可以用标量的反向传播实现</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"></span><br><span class="line"><span class="comment"># f(x) = a*x**2 + b*x + c</span></span><br><span class="line"></span><br><span class="line">x = torch.tensor([[<span class="number">0.0</span>,<span class="number">0.0</span>],[<span class="number">1.0</span>,<span class="number">2.0</span>]],requires_grad = <span class="literal">True</span>) <span class="comment"># x需要被求导</span></span><br><span class="line">a = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line">b = torch.tensor(-<span class="number">2.0</span>)</span><br><span class="line">c = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line">y = a*torch.<span class="built_in">pow</span>(x,<span class="number">2</span>) + b*x + c </span><br><span class="line"></span><br><span class="line">gradient = torch.tensor([[<span class="number">1.0</span>,<span class="number">1.0</span>],[<span class="number">1.0</span>,<span class="number">1.0</span>]])</span><br><span class="line">z = torch.<span class="built_in">sum</span>(y*gradient)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x:&quot;</span>,x)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y:&quot;</span>,y)</span><br><span class="line">z.backward()</span><br><span class="line">x_grad = x.grad</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x_grad:\n&quot;</span>,x_grad)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">x: tensor([[0., 0.],</span></span><br><span class="line"><span class="string">        [1., 2.]], requires_grad=True)</span></span><br><span class="line"><span class="string">y: tensor([[1., 1.],</span></span><br><span class="line"><span class="string">        [0., 1.]], grad_fn=&lt;AddBackward0&gt;)</span></span><br><span class="line"><span class="string">x_grad:</span></span><br><span class="line"><span class="string"> tensor([[-2., -2.],</span></span><br><span class="line"><span class="string">        [ 0.,  2.]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><hr><ul><li>在numpy和torch.tensor中  *  都是指相同size的矩阵各个位置相乘产生新矩阵</li><li>numpy中的矩阵乘法为<code>np.dot(a,b)</code>，torch中为<code>torch.matmul(c,d)</code></li></ul><hr><h4 id="autograd-grad自动微分"><a href="#autograd-grad自动微分" class="headerlink" title="autograd.grad自动微分"></a>autograd.grad自动微分</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"></span><br><span class="line"><span class="comment"># f(x) = a*x**2 + b*x + c的导数</span></span><br><span class="line">x = torch.tensor(<span class="number">0.0</span>,requires_grad = <span class="literal">True</span>) <span class="comment"># x需要被求导</span></span><br><span class="line">a = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line">b = torch.tensor(-<span class="number">2.0</span>)</span><br><span class="line">c = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line">y = a*torch.<span class="built_in">pow</span>(x,<span class="number">2</span>) + b*x + c</span><br><span class="line"></span><br><span class="line"><span class="comment"># create_graph 设置为 True 将允许创建更高阶的导数 </span></span><br><span class="line">dy_dx = torch.autograd.grad(y,x,create_graph=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(dy_dx.data)      <span class="comment"># tensor(-2.)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 求二阶导数</span></span><br><span class="line">dy2_dx2 = torch.autograd.grad(dy_dx,x)[<span class="number">0</span>] </span><br><span class="line"><span class="built_in">print</span>(dy2_dx2.data) <span class="comment"># tensor(2.)</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"></span><br><span class="line">x1 = torch.tensor(<span class="number">1.0</span>,requires_grad = <span class="literal">True</span>) <span class="comment"># x需要被求导</span></span><br><span class="line">x2 = torch.tensor(<span class="number">2.0</span>,requires_grad = <span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y1 = x1*x2</span><br><span class="line">y2 = x1+x2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 允许同时对多个自变量求导数</span></span><br><span class="line">(dy1_dx1,dy1_dx2) = torch.autograd.grad(outputs=y1,inputs = [x1,x2],retain_graph = <span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(dy1_dx1,dy1_dx2)</span><br><span class="line"><span class="comment"># tensor(2.) tensor(1.)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果有多个因变量，相当于把多个因变量的梯度结果求和</span></span><br><span class="line">(dy12_dx1,dy12_dx2) = torch.autograd.grad(outputs=[y1,y2],inputs = [x1,x2])</span><br><span class="line"><span class="built_in">print</span>(dy12_dx1,dy12_dx2)</span><br><span class="line"><span class="comment"># tensor(3.) tensor(2.)</span></span><br></pre></td></tr></table></figure><h4 id="利用autograd和optimizer求最小值"><a href="#利用autograd和optimizer求最小值" class="headerlink" title="利用autograd和optimizer求最小值"></a>利用autograd和optimizer求最小值</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># f(x) = a*x**2 + b*x + c的最小值</span></span><br><span class="line">x = torch.tensor(<span class="number">0.0</span>, requires_grad = <span class="literal">True</span>) <span class="comment"># x需要被求导</span></span><br><span class="line">a = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line">b = torch.tensor(-<span class="number">2.0</span>)</span><br><span class="line">c = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line"></span><br><span class="line">optimizer = torch.optim.SGD(params=[x], lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x</span>):</span><br><span class="line">    result = a*torch.<span class="built_in">pow</span>(x,<span class="number">2</span>) + b*x + c</span><br><span class="line">    <span class="keyword">return</span> (result)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">500</span>):</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    y = f(x)</span><br><span class="line">    y.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;y= <span class="subst">&#123;f(x).data&#125;</span>; x= <span class="subst">&#123;x.data&#125;</span>&quot;</span>) <span class="comment"># f-string格式化</span></span><br><span class="line"><span class="comment"># y= tensor(0.) ; x= tensor(1.0000)</span></span><br></pre></td></tr></table></figure><h3 id="动态计算图"><a href="#动态计算图" class="headerlink" title="动态计算图"></a>动态计算图</h3><p>之前的一些深度学习框架使用静态计算图，而pytorch使用动态计算图，有它的优点</p><h4 id="动态图简介"><a href="#动态图简介" class="headerlink" title="动态图简介"></a>动态图简介</h4><p><img src="https://www.pytorchmaster.com/data/torch%E5%8A%A8%E6%80%81%E5%9B%BE.gif" alt="img"></p><p>pytorch的计算图由<strong>节点</strong>和<strong>边</strong>组成，节点表示<strong>张量</strong>或<strong>Function</strong>,边表示张量和Function之间的依赖关系</p><p>动态有两重含义</p><ul><li>计算图正向传播是立即执行的，无需等待完整的计算图创建完毕，每条语句都会在计算图中动态添加节点和边，并立即执行正向传播得到的计算结果。</li><li>计算图在反向传播后立即销毁。下次调用需要重新构建计算图。如果在程序中使用了backward方法执行了反向传播，或者利用torch.autograd.grad方法计算了梯度，那么创建的计算图会被立即销毁，释放存储空间，下次调用需要重新创建</li></ul><p>1.计算图的正向传播是立即执行的</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line">w = torch.tensor([[<span class="number">3.0</span>,<span class="number">1.0</span>]],requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.tensor([[<span class="number">3.0</span>]],requires_grad=<span class="literal">True</span>)</span><br><span class="line">X = torch.randn(<span class="number">10</span>,<span class="number">2</span>)</span><br><span class="line">Y = torch.randn(<span class="number">10</span>,<span class="number">1</span>)</span><br><span class="line">Y_hat = X@w.t() + b  <span class="comment"># Y_hat定义后其正向传播被立即执行，与其后面的loss创建语句无关</span></span><br><span class="line">loss = torch.mean(torch.<span class="built_in">pow</span>(Y_hat-Y,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(loss.data)</span><br><span class="line"><span class="built_in">print</span>(Y_hat.data)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor(17.8969)</span></span><br><span class="line"><span class="string">tensor([[3.2613],</span></span><br><span class="line"><span class="string">        [4.7322],</span></span><br><span class="line"><span class="string">        [4.5037],</span></span><br><span class="line"><span class="string">        [7.5899],</span></span><br><span class="line"><span class="string">        [7.0973],</span></span><br><span class="line"><span class="string">        [1.3287],</span></span><br><span class="line"><span class="string">        [6.1473],</span></span><br><span class="line"><span class="string">        [1.3492],</span></span><br><span class="line"><span class="string">        [1.3911],</span></span><br><span class="line"><span class="string">        [1.2150]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>2.计算图在反向传播后立即销毁</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line">w = torch.tensor([[<span class="number">3.0</span>,<span class="number">1.0</span>]],requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.tensor([[<span class="number">3.0</span>]],requires_grad=<span class="literal">True</span>)</span><br><span class="line">X = torch.randn(<span class="number">10</span>,<span class="number">2</span>)</span><br><span class="line">Y = torch.randn(<span class="number">10</span>,<span class="number">1</span>)</span><br><span class="line">Y_hat = X@w.t() + b  <span class="comment"># Y_hat定义后其正向传播被立即执行，与其后面的loss创建语句无关</span></span><br><span class="line">loss = torch.mean(torch.<span class="built_in">pow</span>(Y_hat-Y,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算图在反向传播后立即销毁，如果需要保留计算图, 需要设置retain_graph = True</span></span><br><span class="line">loss.backward()  <span class="comment">#loss.backward(retain_graph = True) </span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss.backward() <span class="comment">#如果再次执行反向传播将报错</span></span><br></pre></td></tr></table></figure><p>RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph&#x3D;True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.</p><p>第二次尝试向后遍历图形（或在张量已被释放后直接访问已保存的张量）。当您调用 .backward() 或 autograd.grad() 时，图形的已保存中间值将被释放。如果您需要第二次向后遍历图形，或者如果您需要在向后调用后访问保存的张量，请指定 retain_graph&#x3D;True。</p><h4 id="计算图中的Function"><a href="#计算图中的Function" class="headerlink" title="计算图中的Function"></a>计算图中的Function</h4><p>计算图中除了张量的另外一种节点是<code>Function</code>, 实际上就是 Pytorch中各种对张量操作的函数</p><p>这些Function和我们python中的函数有一个较大的区别，那就是它<strong>同时包含正向计算逻辑和反向传播逻辑</strong></p><p>我们可以通过继承torch.autograd.Function来创建这种支持反向传播的Function</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyReLU</span>(torch.autograd.Function):</span><br><span class="line">    <span class="comment"># 正向传播逻辑，可以用ctx存储一些值，供反向传播使用</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">ctx, <span class="built_in">input</span></span>):</span><br><span class="line">        ctx.save_for_backward(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">input</span>.clamp(<span class="built_in">min</span>=<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 反向传播逻辑</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">backward</span>(<span class="params">ctx, grad_output</span>):</span><br><span class="line">        <span class="built_in">input</span>, = ctx.saved_tensors</span><br><span class="line">        grad_input = grad_output.clone()</span><br><span class="line">        grad_input[<span class="built_in">input</span> &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> grad_input</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line">w = torch.tensor([[<span class="number">3.0</span>,<span class="number">1.0</span>]],requires_grad=<span class="literal">True</span>)</span><br><span class="line">b = torch.tensor([[<span class="number">3.0</span>]],requires_grad=<span class="literal">True</span>)</span><br><span class="line">X = torch.tensor([[-<span class="number">1.0</span>,-<span class="number">1.0</span>],[<span class="number">1.0</span>,<span class="number">1.0</span>]])</span><br><span class="line">Y = torch.tensor([[<span class="number">2.0</span>,<span class="number">3.0</span>]])</span><br><span class="line"></span><br><span class="line">relu = MyReLU.apply <span class="comment"># relu现在也可以具有正向传播和反向传播功能</span></span><br><span class="line">Y_hat = relu(X@w.t() + b)</span><br><span class="line">loss = torch.mean(torch.<span class="built_in">pow</span>(Y_hat-Y,<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(w.grad)<span class="comment">#tensor([[4.5000, 4.5000]])</span></span><br><span class="line"><span class="built_in">print</span>(b.grad)<span class="comment">#tensor([[4.5000]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Y_hat的梯度函数即是我们自己所定义的 MyReLU.backward</span></span><br><span class="line"><span class="built_in">print</span>(Y_hat.grad_fn)<span class="comment">#&lt;torch.autograd.function.MyReLUBackward object at 0x1205a46c8&gt;</span></span><br></pre></td></tr></table></figure><h4 id="计算图与反向传播"><a href="#计算图与反向传播" class="headerlink" title="计算图与反向传播"></a>计算图与反向传播</h4><p>简单理解反向传播的原理和过程（链式法则）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.tensor(<span class="number">3.0</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line">y1 = x + <span class="number">1</span></span><br><span class="line">y2 = <span class="number">2</span>*x</span><br><span class="line">loss = (y1-y2)**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">loss.backward()</span><br></pre></td></tr></table></figure><p>loss.backward()语句调用后，依次发生以下计算过程。</p><ol><li><p>loss自己的grad梯度赋值为1，即对自身的梯度为1。</p></li><li><p>loss根据其自身梯度以及关联的backward方法，计算出其对应的自变量即y1和y2的梯度，将该值赋值到y1.grad和y2.grad。</p></li><li><p>y2和y1根据其自身梯度以及关联的backward方法, 分别计算出其对应的自变量x的梯度，x.grad将其收到的多个梯度值累加。</p></li></ol><p>（注意，1,2,3步骤的求梯度顺序和对多个梯度值的累加规则恰好是求导链式法则的程序表述）</p><p>正因为求导链式法则衍生的梯度累加规则，张量的grad梯度不会自动清零，在需要的时候需要手动置零。</p><h4 id="叶子节点和非叶子节点"><a href="#叶子节点和非叶子节点" class="headerlink" title="叶子节点和非叶子节点"></a>叶子节点和非叶子节点</h4><p>执行<a href="#jump">上述代码</a>，我们会发现loss.grad并不是我们期望的1，而是None。类似地 y1.grad 以及 y2.grad也是 None。</p><p>这是<strong>由于它们不是叶子节点张量</strong>。</p><p>在反向传播过程中，只有 <code>is_leaf=True</code> 的叶子节点，需要求导的张量的导数结果才会被最后保留下来。</p><p>那么什么是叶子节点张量呢？叶子节点张量需要满足两个条件。</p><p>1，叶子节点张量是由用户直接创建的张量，而非由某个Function通过计算得到的张量。</p><p>2，叶子节点张量的 requires_grad属性必须为True.</p><p>Pytorch设计这样的规则主要是为了节约内存或者显存空间，因为几乎所有的时候，用户只会关心他自己直接创建的张量的梯度。</p><p>所有依赖于叶子节点张量的张量, 其requires_grad 属性必定是True的，但其梯度值只在计算过程中被用到，不会最终存储到grad属性中。</p><p>如果需要保留中间计算结果的梯度到grad属性中，可以使用 retain_grad方法。 如果仅仅是为了调试代码查看梯度值，可以利用register_hook打印日志。<span id="jump"></span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.tensor(<span class="number">3.0</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">y1 = x + <span class="number">1</span></span><br><span class="line">y2 = <span class="number">2</span>*x</span><br><span class="line">loss = (y1-y2)**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">loss.backward()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;loss.grad:&quot;</span>, loss.grad) <span class="comment"># loss.grad: None</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y1.grad:&quot;</span>, y1.grad)<span class="comment"># y1.grad: None</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;y2.grad:&quot;</span>, y2.grad)<span class="comment"># y2.grad: None</span></span><br><span class="line"><span class="built_in">print</span>(x.grad)<span class="comment"># tensor(4.)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x.is_leaf) <span class="comment"># True</span></span><br><span class="line"><span class="built_in">print</span>(y1.is_leaf) <span class="comment"># False</span></span><br><span class="line"><span class="built_in">print</span>(y2.is_leaf) <span class="comment"># False</span></span><br><span class="line"><span class="built_in">print</span>(loss.is_leaf)<span class="comment"># False</span></span><br></pre></td></tr></table></figure><p>利用retain_grad可以保留非叶子节点的梯度值，利用register_hook可以查看非叶子节点的梯度值</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"></span><br><span class="line"><span class="comment">#正向传播</span></span><br><span class="line">x = torch.tensor(<span class="number">3.0</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line">y1 = x + <span class="number">1</span></span><br><span class="line">y2 = <span class="number">2</span>*x</span><br><span class="line">loss = (y1-y2)**<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#非叶子节点梯度显示控制</span></span><br><span class="line">y1.register_hook(<span class="keyword">lambda</span> grad: <span class="built_in">print</span>(<span class="string">&#x27;y1 grad: &#x27;</span>, grad))<span class="comment"># y2 grad:  tensor(4.)</span></span><br><span class="line">y2.register_hook(<span class="keyword">lambda</span> grad: <span class="built_in">print</span>(<span class="string">&#x27;y2 grad: &#x27;</span>, grad))<span class="comment"># y1 grad:  tensor(-4.)</span></span><br><span class="line">loss.retain_grad()</span><br><span class="line"></span><br><span class="line"><span class="comment">#反向传播</span></span><br><span class="line">loss.backward()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;loss.grad:&quot;</span>, loss.grad)<span class="comment"># loss.grad: tensor(1.)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;x.grad:&quot;</span>, x.grad) <span class="comment"># loss.grad: tensor(1.)</span></span><br></pre></td></tr></table></figure><h4 id="计算图在TensorBoard中的可视化"><a href="#计算图在TensorBoard中的可视化" class="headerlink" title="计算图在TensorBoard中的可视化"></a>计算图在TensorBoard中的可视化</h4><p>可以利用 torch.utils.tensorboard 将计算图导出到 TensorBoard进行可视化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        self.w = nn.Parameter(torch.randn(<span class="number">2</span>,<span class="number">1</span>))</span><br><span class="line">        self.b = nn.Parameter(torch.zeros(<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        y = x@self.w + self.b</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;./data/tensorboard&#x27;</span>)</span><br><span class="line">writer.add_graph(net,input_to_model = torch.rand(<span class="number">10</span>,<span class="number">2</span>))</span><br><span class="line">writer.close()</span><br><span class="line"></span><br><span class="line">%load_ext tensorboard</span><br><span class="line"><span class="comment">#%tensorboard --logdir ./data/tensorboard</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorboard <span class="keyword">import</span> notebook</span><br><span class="line">notebook.<span class="built_in">list</span>() </span><br><span class="line"></span><br><span class="line"><span class="comment">#在tensorboard中查看模型</span></span><br><span class="line">notebook.start(<span class="string">&quot;--logdir ./data/tensorboard&quot;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://www.pytorchmaster.com/data/2-3-%E8%AE%A1%E7%AE%97%E5%9B%BE%E5%8F%AF%E8%A7%86%E5%8C%96.png" alt="img"></p><h3 id="pytorch的层次结构"><a href="#pytorch的层次结构" class="headerlink" title="pytorch的层次结构"></a>pytorch的层次结构</h3><p>5个不同的层次结构：即硬件层，内核层，低阶API，中阶API，高阶API [torchkeras]</p><p>Pytorch的层次结构从低到高可以分成如下五层。</p><p>最底层为硬件层，Pytorch支持CPU、GPU加入计算资源池。</p><p>第二层为C++实现的内核。</p><p>第三层为Python实现的操作符，提供了封装C++内核的低级API指令，主要包括各种张量操作算子、自动微分、变量管理. 如torch.tensor,torch.cat,torch.autograd.grad,nn.Module. 如果把模型比作一个房子，那么第三层API就是【模型之砖】。</p><p>第四层为Python实现的模型组件，对低级API进行了函数封装，主要包括各种模型层，损失函数，优化器，数据管道等等。 如torch.nn.Linear,torch.nn.BCE,torch.optim.Adam,torch.utils.data.DataLoader. 如果把模型比作一个房子，那么第四层API就是【模型之墙】。</p><p>第五层为Python实现的模型接口。Pytorch没有官方的高阶API。为了便于训练模型，<a href="https://github.com/lyhue1991/eat_pytorch_in_20_days">博客作者</a>仿照keras中的模型接口，使用了不到300行代码，封装了Pytorch的高阶模型接口torchkeras.Model。如果把模型比作一个房子，那么第五层API就是模型本身，即【模型之屋】。</p><h4 id="低阶API示范"><a href="#低阶API示范" class="headerlink" title="低阶API示范"></a>低阶API示范</h4><p>下面的范例使用Pytorch的低阶API实现线性回归模型和DNN二分类模型</p><p>低阶API主要包括<strong>张量操作</strong>，<strong>计算图</strong>和<strong>自动微分</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="comment">#打印时间</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">printbar</span>():</span><br><span class="line">    nowtime = datetime.datetime.now().strftime(<span class="string">&#x27;%Y-%m-%d %H:%M:%S&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>+<span class="string">&quot;==========&quot;</span>*<span class="number">8</span> + <span class="string">&quot;%s&quot;</span>%nowtime)</span><br><span class="line"></span><br><span class="line"><span class="comment"># mac系统上pytorch和matplotlib在jupyter中同时跑需要更改环境变量</span></span><br><span class="line"><span class="comment"># os.environ[&quot;KMP_DUPLICATE_LIB_OK&quot;]=&quot;TRUE&quot; </span></span><br></pre></td></tr></table></figure><h5 id="一、线性回归模型"><a href="#一、线性回归模型" class="headerlink" title="一、线性回归模型"></a>一、线性回归模型</h5><ol><li>data prepare</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt </span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#样本数量</span></span><br><span class="line">n = <span class="number">400</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成测试用数据集</span></span><br><span class="line">X = <span class="number">10</span>*torch.rand([n,<span class="number">2</span>])-<span class="number">5.0</span>  <span class="comment">#torch.rand是均匀分布 </span></span><br><span class="line">w0 = torch.tensor([[<span class="number">2.0</span>],[-<span class="number">3.0</span>]])</span><br><span class="line">b0 = torch.tensor([[<span class="number">10.0</span>]])</span><br><span class="line">Y = X@w0 + b0 + torch.normal( <span class="number">0.0</span>,<span class="number">2.0</span>,size = [n,<span class="number">1</span>])  <span class="comment"># @表示矩阵乘法,增加正态扰动</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据可视化</span></span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">&#x27;svg&#x27;</span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize = (<span class="number">12</span>,<span class="number">5</span>))  <span class="comment"># 图形窗口的宽度为 12 英寸，高度为 5 英寸</span></span><br><span class="line">ax1 = plt.subplot(<span class="number">121</span>)</span><br><span class="line"><span class="comment">#画散点图 </span></span><br><span class="line">ax1.scatter(X[:,<span class="number">0</span>].numpy(),Y[:,<span class="number">0</span>].numpy(), c = <span class="string">&quot;b&quot;</span>,label = <span class="string">&quot;samples&quot;</span>)</span><br><span class="line"><span class="comment">#设置图例</span></span><br><span class="line">ax1.legend()  <span class="comment"># 没有此不会有samples图例</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;x1&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;y&quot;</span>,rotation = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">ax2 = plt.subplot(<span class="number">122</span>)</span><br><span class="line">ax2.scatter(X[:,<span class="number">1</span>].numpy(),Y[:,<span class="number">0</span>].numpy(), c = <span class="string">&quot;g&quot;</span>,label = <span class="string">&quot;samples&quot;</span>)</span><br><span class="line">ax2.legend()</span><br><span class="line">plt.xlabel(<span class="string">&quot;x2&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;y&quot;</span>,rotation = <span class="number">0</span>)</span><br></pre></td></tr></table></figure><p><img src="https://haoming2003.oss-cn-hangzhou.aliyuncs.com/image-20230119174857563.png" alt="image-20230119174857563"></p><p>注：**<code>plt.subplot(121)</code> 是 matplotlib 库中用于创建多个子图的函数之一。其中，<code>121</code> 是参数，表示将整个图分成 1 行 2 列，并在第 1 个位置创建子图。因此，这条语句将创建一个 1 行 2 列的子图网格，并在第一个子图中绘制图形。**</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建数据管道迭代器</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">data_iter</span>(<span class="params">features, labels, batch_size=<span class="number">8</span></span>):</span><br><span class="line">    num_examples = <span class="built_in">len</span>(features)</span><br><span class="line">    indices = <span class="built_in">list</span>(<span class="built_in">range</span>(num_examples))</span><br><span class="line">    np.random.shuffle(indices)  <span class="comment">#样本的读取顺序是随机的</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, num_examples, batch_size):</span><br><span class="line">        indexs = torch.LongTensor(indices[i: <span class="built_in">min</span>(i + batch_size, num_examples)])</span><br><span class="line">        <span class="keyword">yield</span>  features.index_select(<span class="number">0</span>, indexs), labels.index_select(<span class="number">0</span>, indexs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试数据管道效果   </span></span><br><span class="line">batch_size = <span class="number">8</span></span><br><span class="line">(features,labels) = <span class="built_in">next</span>(data_iter(X,Y,batch_size))</span><br><span class="line"><span class="built_in">print</span>(features)</span><br><span class="line"><span class="built_in">print</span>(labels)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">tensor([[ 1.0449, -0.3581],</span></span><br><span class="line"><span class="string">        [-3.0645, -2.9230],</span></span><br><span class="line"><span class="string">        [ 3.7969, -4.5846],</span></span><br><span class="line"><span class="string">        [-0.2429,  0.5349],</span></span><br><span class="line"><span class="string">        [ 2.2708,  0.1713],</span></span><br><span class="line"><span class="string">        [ 4.6910,  4.3684],</span></span><br><span class="line"><span class="string">        [ 2.1360, -4.7411],</span></span><br><span class="line"><span class="string">        [ 3.3687,  0.3648]])</span></span><br><span class="line"><span class="string">tensor([[15.6397],</span></span><br><span class="line"><span class="string">        [14.1632],</span></span><br><span class="line"><span class="string">        [31.6240],</span></span><br><span class="line"><span class="string">        [ 7.4723],</span></span><br><span class="line"><span class="string">        [11.8881],</span></span><br><span class="line"><span class="string">        [ 6.8064],</span></span><br><span class="line"><span class="string">        [30.4618],</span></span><br><span class="line"><span class="string">        [15.2579]])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><ol start="2"><li>define the model</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearRegression</span>: </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.w = torch.randn_like(w0,requires_grad=<span class="literal">True</span>)</span><br><span class="line">        self.b = torch.zeros_like(b0,requires_grad=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment">#正向传播</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>): </span><br><span class="line">        <span class="keyword">return</span> x@self.w + self.b</span><br><span class="line">    <span class="comment"># 损失函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loss_func</span>(<span class="params">self,y_pred,y_true</span>):  </span><br><span class="line">        <span class="keyword">return</span> torch.mean((y_pred - y_true)**<span class="number">2</span>/<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">model = LinearRegression()</span><br></pre></td></tr></table></figure><ol start="3"><li>model training</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">model, features, labels</span>):</span><br><span class="line">    predictions = model.forward(features)</span><br><span class="line">    loss = model.loss_func(predictions,labels)</span><br><span class="line">    <span class="comment"># 反向传播求梯度</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 使用torch.no_grad()避免梯度记录，也可以通过操作 model.w.data 实现避免梯度记录 </span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment"># 梯度下降法更新参数</span></span><br><span class="line">        model.w -= <span class="number">0.001</span>*model.w.grad</span><br><span class="line">        model.b -= <span class="number">0.001</span>*model.b.grad</span><br><span class="line">        <span class="comment"># 梯度清零</span></span><br><span class="line">        model.w.grad.zero_()</span><br><span class="line">        model.b.grad.zero_()</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试train_step效果</span></span><br><span class="line">batch_size = <span class="number">10</span></span><br><span class="line">(features,labels) = <span class="built_in">next</span>(data_iter(X,Y,batch_size))</span><br><span class="line">train_step(model,features,labels)</span><br></pre></td></tr></table></figure><p>Out[]: tensor(141.2280, grad_fn&#x3D;<MeanBackward0>)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">model,epochs</span>):</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,epochs+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> features, labels <span class="keyword">in</span> data_iter(X,Y,<span class="number">10</span>):</span><br><span class="line">            loss = train_step(model,features,labels)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch%<span class="number">200</span>==<span class="number">0</span>:</span><br><span class="line">            printbar()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;epoch =&quot;</span>,epoch,<span class="string">&quot;loss = &quot;</span>,loss.item())</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;model.w =&quot;</span>,model.w.data)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;model.b =&quot;</span>,model.b.data)</span><br><span class="line"></span><br><span class="line">train_model(model,epochs = <span class="number">1000</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">================================================================================2023-01-20 17:03:37</span><br><span class="line">epoch = 200 loss =  2.0936481952667236</span><br><span class="line">model.w = tensor([[ 2.0185],</span><br><span class="line">        [-2.9519]])</span><br><span class="line">model.b = tensor([[10.0203]])</span><br><span class="line"></span><br><span class="line">================================================================================2023-01-20 17:03:38</span><br><span class="line">epoch = 400 loss =  1.3962600231170654</span><br><span class="line">model.w = tensor([[ 2.0212],</span><br><span class="line">        [-2.9512]])</span><br><span class="line">model.b = tensor([[10.0241]])</span><br><span class="line"></span><br><span class="line">================================================================================2023-01-20 17:03:39</span><br><span class="line">epoch = 600 loss =  0.3997553586959839</span><br><span class="line">model.w = tensor([[ 2.0167],</span><br><span class="line">        [-2.9528]])</span><br><span class="line">model.b = tensor([[10.0237]])</span><br><span class="line"></span><br><span class="line">================================================================================2023-01-20 17:03:41</span><br><span class="line">epoch = 800 loss =  1.8717002868652344</span><br><span class="line">model.w = tensor([[ 2.0194],</span><br><span class="line">        [-2.9495]])</span><br><span class="line">model.b = tensor([[10.0240]])</span><br><span class="line"></span><br><span class="line">================================================================================2023-01-20 17:03:42</span><br><span class="line">epoch = 1000 loss =  1.8542640209197998</span><br><span class="line">model.w = tensor([[ 2.0176],</span><br><span class="line">        [-2.9507]])</span><br><span class="line">model.b = tensor([[10.0237]])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 结果可视化</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">plt.figure(figsize = (<span class="number">12</span>,<span class="number">5</span>))</span><br><span class="line">ax1 = plt.subplot(<span class="number">121</span>)</span><br><span class="line">ax1.scatter(X[:,<span class="number">0</span>].numpy(),Y[:,<span class="number">0</span>].numpy(), c = <span class="string">&quot;b&quot;</span>,label = <span class="string">&quot;samples&quot;</span>)</span><br><span class="line">ax1.plot(X[:,<span class="number">0</span>].numpy(),(model.w[<span class="number">0</span>].data*X[:,<span class="number">0</span>]+model.b[<span class="number">0</span>].data).numpy(),<span class="string">&quot;-r&quot;</span>,linewidth = <span class="number">5.0</span>,label = <span class="string">&quot;model&quot;</span>)</span><br><span class="line">ax1.legend()</span><br><span class="line">plt.xlabel(<span class="string">&quot;x1&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;y&quot;</span>,rotation = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ax2 = plt.subplot(<span class="number">122</span>)</span><br><span class="line">ax2.scatter(X[:,<span class="number">1</span>].numpy(),Y[:,<span class="number">0</span>].numpy(), c = <span class="string">&quot;g&quot;</span>,label = <span class="string">&quot;samples&quot;</span>)</span><br><span class="line">ax2.plot(X[:,<span class="number">1</span>].numpy(),(model.w[<span class="number">1</span>].data*X[:,<span class="number">1</span>]+model.b[<span class="number">0</span>].data).numpy(),<span class="string">&quot;-r&quot;</span>,linewidth = <span class="number">5.0</span>,label = <span class="string">&quot;model&quot;</span>)</span><br><span class="line">ax2.legend()</span><br><span class="line">plt.xlabel(<span class="string">&quot;x2&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;y&quot;</span>,rotation = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://haoming2003.oss-cn-hangzhou.aliyuncs.com/image-20230120170539911.png" alt="image-20230120170539911"></p><h5 id="二、DNN二分类模型"><a href="#二、DNN二分类模型" class="headerlink" title="二、DNN二分类模型"></a>二、DNN二分类模型</h5><ol><li>data prepare</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd </span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">&#x27;svg&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#正负样本数量</span></span><br><span class="line">n_positive,n_negative = <span class="number">2000</span>,<span class="number">2000</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#生成正样本, 小圆环分布</span></span><br><span class="line">r_p = <span class="number">5.0</span> + torch.normal(<span class="number">0.0</span>,<span class="number">1.0</span>,size = [n_positive,<span class="number">1</span>]) </span><br><span class="line">theta_p = <span class="number">2</span>*np.pi*torch.rand([n_positive,<span class="number">1</span>])</span><br><span class="line">Xp = torch.cat([r_p*torch.cos(theta_p),r_p*torch.sin(theta_p)],axis = <span class="number">1</span>)</span><br><span class="line">Yp = torch.ones_like(r_p)</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成负样本, 大圆环分布</span></span><br><span class="line">r_n = <span class="number">8.0</span> + torch.normal(<span class="number">0.0</span>,<span class="number">1.0</span>,size = [n_negative,<span class="number">1</span>]) </span><br><span class="line">theta_n = <span class="number">2</span>*np.pi*torch.rand([n_negative,<span class="number">1</span>])</span><br><span class="line">Xn = torch.cat([r_n*torch.cos(theta_n),r_n*torch.sin(theta_n)],axis = <span class="number">1</span>)</span><br><span class="line">Yn = torch.zeros_like(r_n)</span><br><span class="line"></span><br><span class="line"><span class="comment">#汇总样本</span></span><br><span class="line">X = torch.cat([Xp,Xn],axis = <span class="number">0</span>)</span><br><span class="line">Y = torch.cat([Yp,Yn],axis = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#可视化</span></span><br><span class="line">plt.figure(figsize = (<span class="number">6</span>,<span class="number">6</span>))</span><br><span class="line">plt.scatter(Xp[:,<span class="number">0</span>].numpy(),Xp[:,<span class="number">1</span>].numpy(),c = <span class="string">&quot;r&quot;</span>)</span><br><span class="line">plt.scatter(Xn[:,<span class="number">0</span>].numpy(),Xn[:,<span class="number">1</span>].numpy(),c = <span class="string">&quot;g&quot;</span>)</span><br><span class="line">plt.legend([<span class="string">&quot;positive&quot;</span>,<span class="string">&quot;negative&quot;</span>]);</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python小知识点</title>
      <link href="/2023/01/04/python%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
      <url>/2023/01/04/python%E5%B0%8F%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
      
        <content type="html"><![CDATA[<p>python小知识点</p><h4 id="可变类型拷贝"><a href="#可变类型拷贝" class="headerlink" title="可变类型拷贝"></a>可变类型拷贝</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;raw data.txt&quot;</span>,<span class="string">&quot;r&quot;</span>)<span class="keyword">as</span> f:</span><br><span class="line">raw data f.readlines()</span><br><span class="line">raw_data [[<span class="built_in">int</span>(i)<span class="keyword">for</span> i <span class="keyword">in</span> data.strip().split(<span class="string">&quot;&quot;</span>)<span class="keyword">for</span> data <span class="keyword">in</span> raw data]</span><br><span class="line"><span class="comment">#[[1,2,3,4,5],[6,7,8,9,0],[2,2,2,2,2],[4,4,4,4,4],[6,7,1,9,8]]</span></span><br><span class="line"></span><br><span class="line">raw_data_copy = rawdata.copy() <span class="comment"># 一维数据copy样拷贝还会改变原数据</span></span><br><span class="line">raw_data_copy = copy.deepcopy(raw_data)  <span class="comment">#多维数据拷贝</span></span><br><span class="line">fraw_data_copy[<span class="number">0</span>][<span class="number">0</span>]<span class="number">99999</span></span><br><span class="line"><span class="built_in">print</span>(raw_data)</span><br><span class="line"><span class="comment">#[1,2,3,4,5],[6,7,8,9,0],[2,2,2,2,2],[4,4,</span></span><br><span class="line"><span class="number">4</span>,<span class="number">4</span>,<span class="number">4</span>],<span class="number">6</span>,<span class="number">7</span>,<span class="number">1</span>,<span class="number">9</span>,<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p>函数默认参数为可变类型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add_fruit</span>(<span class="params">fruit,fruit <span class="built_in">list</span>=[]</span>):</span><br><span class="line">fruit_list.append(fruit)</span><br><span class="line"><span class="built_in">print</span>(fruit_list)</span><br><span class="line">fruits=[<span class="string">&#x27;banana&#x27;</span>,<span class="string">&#x27;apple&#x27;</span>]</span><br><span class="line">add_fruit(<span class="string">&#x27;watermelon&#x27;</span>,fruits)</span><br><span class="line">[<span class="string">&#x27;banana&#x27;</span>,<span class="string">&#x27;apple&#x27;</span>,<span class="string">&#x27;watermelon&#x27;</span>]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add_fruit</span>(<span class="params">fruit,fruit <span class="built_in">list</span>=[]</span>):</span><br><span class="line">fruit_list.append(fruit)</span><br><span class="line"><span class="built_in">print</span>(fruit_list)</span><br><span class="line"></span><br><span class="line">add fruit(<span class="string">&#x27;watermelon&#x27;</span>) <span class="comment">#[&#x27;watermelon&#x27;]</span></span><br><span class="line">add fruit(<span class="string">&#x27;banana&#x27;</span>)  <span class="comment">#[&#x27;watermelon&#x27;, &#x27;banana&#x27;]</span></span><br></pre></td></tr></table></figure><p>由于可变，所以fruit_list会在前面的基础上调用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">add_fruit</span>(<span class="params">fruit,fruit <span class="built_in">list</span>=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> fruit_list <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        fruit_list = []</span><br><span class="line">fruit_list.append(fruit)</span><br><span class="line"><span class="built_in">print</span>(fruit_list)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(add_fruit.__defaults__ ) <span class="comment"># (None, )</span></span><br><span class="line">add_fruit(<span class="string">&#x27;watermelon&#x27;</span>) <span class="comment"># [&#x27;watermelon&#x27;]</span></span><br><span class="line"><span class="built_in">print</span>(add_fruit.__defaults__ ) <span class="comment"># (None, )</span></span><br><span class="line">add_ fruit( <span class="string">&#x27;banana&#x27;</span> ) <span class="comment">#[&#x27;banana&#x27;]</span></span><br><span class="line"><span class="built_in">print</span>(add_fruit.__defaults__ ) <span class="comment"># (None, )</span></span><br></pre></td></tr></table></figure><p>所以尽可能避免将可变类型作为默认参数，而是在内部判断</p><h4 id="函数默认值属性"><a href="#函数默认值属性" class="headerlink" title="函数默认值属性"></a>函数默认值属性</h4><p><strong>在定义时就被确定了</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">display_time</span>(<span class="params">data=datetime.now(<span class="params"> </span>)</span>) :</span><br><span class="line"><span class="built_in">print</span>(data.strftime(<span class="string">&#x27;%B %d, %Y %H:%M:%S&#x27;</span>))</span><br><span class="line"><span class="built_in">print</span> (display_time.__defaults__ ) <span class="comment"># (datetime.datetime (2022,11,26,17, 4, 53, 360783), )</span></span><br><span class="line">display_time() <span class="comment"># November 26, 2022 17 :04:53</span></span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line">display_time() <span class="comment"># November 26, 2022 17 :04:53 </span></span><br><span class="line">time.sleep(<span class="number">2</span>)</span><br><span class="line">display_time() <span class="comment"># November 26, 2022 17 :04:53</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>修改</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">display_time</span>(<span class="params">data=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> data <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        data = datatime.Now()</span><br><span class="line"><span class="built_in">print</span>(data.strftime(<span class="string">&#x27;%B %d, %Y %H:%M:%S&#x27;</span>))</span><br></pre></td></tr></table></figure><h4 id="下划线的含义"><a href="#下划线的含义" class="headerlink" title="下划线的含义"></a>下划线的含义</h4><p>· 单引号下划线： <code>_var</code></p><p>单下划线是一种Python命名约定，表示某个名称是供内部使用的，只是对程序员的提示，不会有多余的效果</p><p>· 单尾划线： <code>var_</code></p><p>一个变量最合适的名字已经被一个关键字代替了等情况，打破命名冲突</p><p>· 双领先下划线： <code>__var</code></p><p>双下划线前缀导致Python解释器重写属性名，以避免子类中的命名冲突</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Test</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.foo = <span class="number">11</span></span><br><span class="line">        self._bar = <span class="number">23</span></span><br><span class="line">        self.__baz = <span class="number">23</span></span><br><span class="line">        </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t = Test()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">dir</span>(t)</span><br><span class="line">[<span class="string">&#x27;_Test__baz&#x27;</span>, <span class="string">&#x27;__class__&#x27;</span>, <span class="string">&#x27;__delattr__&#x27;</span>, <span class="string">&#x27;__dict__&#x27;</span>, <span class="string">&#x27;__dir__&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;__doc__&#x27;</span>, <span class="string">&#x27;__eq__&#x27;</span>, <span class="string">&#x27;__format__&#x27;</span>, <span class="string">&#x27;__ge__&#x27;</span>, <span class="string">&#x27;__getattribute__&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;__gt__&#x27;</span>, <span class="string">&#x27;__hash__&#x27;</span>, <span class="string">&#x27;__init__&#x27;</span>, <span class="string">&#x27;__le__&#x27;</span>, <span class="string">&#x27;__lt__&#x27;</span>, <span class="string">&#x27;__module__&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;__ne__&#x27;</span>, <span class="string">&#x27;__new__&#x27;</span>, <span class="string">&#x27;__reduce__&#x27;</span>, <span class="string">&#x27;__reduce_ex__&#x27;</span>, <span class="string">&#x27;__repr__&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;__setattr__&#x27;</span>, <span class="string">&#x27;__sizeof__&#x27;</span>, <span class="string">&#x27;__str__&#x27;</span>, <span class="string">&#x27;__subclasshook__&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;__weakref__&#x27;</span>, <span class="string">&#x27;_bar&#x27;</span>, <span class="string">&#x27;foo&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t.__dict__</span><br><span class="line">&#123;<span class="string">&#x27;foo&#x27;</span>: <span class="number">11</span>, <span class="string">&#x27;_bar&#x27;</span>: <span class="number">23</span>, <span class="string">&#x27;_Test__baz&#x27;</span>: <span class="number">23</span>&#125;</span><br></pre></td></tr></table></figure><p>补充<code>__dict__</code>的博客：<a href="http://c.biancheng.net/view/2374.html">http://c.biancheng.net/view/2374.html</a></p><p>可以看到<code>foo</code>和<code>_bar</code>的变量属性均未被修改，但是<code>__baz</code>被修改为<code>_Test__baz</code>,为了保护变量不被子类覆盖</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ManglingTest</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        self.__mangled = <span class="string">&#x27;hello&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_mangled</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> self.__mangled</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ManglingTest().get_mangled()</span><br><span class="line"><span class="string">&#x27;hello&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>ManglingTest().__mangled</span><br><span class="line">AttributeError: <span class="string">&quot;&#x27;ManglingTest&#x27; object has no attribute &#x27;__mangled&#x27;&quot;</span></span><br></pre></td></tr></table></figure><p>· 领先和落后双下划线： <code>__var__</code></p><p>Python中存在一些特殊的方法，有些方法以双下划线<code>__</code>开头和结尾，它们是Python的魔法函数，比如<code>__init__()</code>和<code>__str__</code>等等。<strong>不用要这种方式命名自己的变量或者函数</strong></p><hr><p>魔法函数是指类内部以双下划线开头，并且以双下划线结尾的函数，在特定时刻，Python会自动调用这些函数</p><hr><p><a href="https://www.cnblogs.com/chenhuabin/p/13752770.html#_label0">https://www.cnblogs.com/chenhuabin/p/13752770.html#_label0</a></p><p>· 单下划线： <code>_</code></p><p>一个单独的下划线有时用作一个名称，表示一个变量是临时的或是不重要的</p><h4 id="filter、map、reduce、apply"><a href="#filter、map、reduce、apply" class="headerlink" title="filter、map、reduce、apply"></a>filter、map、reduce、apply</h4><ul><li>filter(function，sequence)</li></ul><p><strong>过滤掉序列中不符合函数条件的元素</strong>,返回迭代器,需要list转列表等</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(<span class="built_in">filter</span>(<span class="keyword">lambda</span> x:x%<span class="number">2</span>==<span class="number">0</span>,x))) <span class="comment"># 找出偶数。python3.*之后filter函数返回的不再是列表而是迭代器，所以需要用list转换。</span></span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">[<span class="number">2</span>, <span class="number">4</span>]</span><br></pre></td></tr></table></figure><ul><li>map(function,iterable1,iterable2)</li></ul><p><strong>求一个序列或者多个序列进行函数映射之后的值</strong>，就该想到map这个函数,返回迭代器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]</span><br><span class="line">y = [<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x,y:(x*y)+<span class="number">2</span>,x,y)))</span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line">[<span class="number">4</span>, <span class="number">8</span>, <span class="number">14</span>, <span class="number">22</span>, <span class="number">32</span>]</span><br></pre></td></tr></table></figure><ul><li>reduce（function，iterable）</li></ul><p><strong>对一个序列进行压缩运算，得到一个值</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line">arr = [<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line">reduce(<span class="keyword">lambda</span> x,y: x + y,arr) <span class="comment"># 直接返回一个值</span></span><br><span class="line"><span class="comment"># 20</span></span><br></pre></td></tr></table></figure><p>其计算原理：<br>先计算头两个元素：f(2, 3)，结果为5；<br>再把结果和第3个元素计算：f(5, 4)，结果为9；<br>再把结果和第4个元素计算：f(9, 5)，结果为14；<br>再把结果和第5个元素计算：f(14, 6)，结果为20；<br>由于没有更多的元素了，计算结束，返回结果20。</p><ul><li>apply(function,axis)</li></ul><p>pandas中的函数，eg:   <code>data.apply(lambda x:x*10)</code></p><hr><p>filter和map都是python内置的函数，可以直接调用，reduce在functools模块，apply在pandas模块</p><hr><h4 id="yield"><a href="#yield" class="headerlink" title="yield"></a>yield</h4><p>带有 yield 的函数在 Python 中被称之为 generator（生成器）</p><p>博客：<a href="https://blog.csdn.net/mieleizhi0522/article/details/82142856">https://blog.csdn.net/mieleizhi0522/article/details/82142856</a></p><h4 id="python数值"><a href="#python数值" class="headerlink" title="python数值"></a>python数值</h4><ul><li><strong>整型(int)</strong> - 通常被称为是整型或整数，是正或负整数，不带小数点。Python3 整型是没有限制大小的，可以当作 Long 类型使用，所以 Python3 没有 Python2 的 Long 类型。布尔(bool)是整型的子类型。</li><li><strong>浮点型(float)</strong> - 浮点型由整数部分与小数部分组成，浮点型也可以使用科学计数法表示（2.5e2 &#x3D; 2.5 x 102 &#x3D; 250）</li><li><strong>复数( (complex))</strong> - 复数由实数部分和虚数部分构成，可以用a + bj,或者complex(a,b)表示， 复数的实部a和虚部b都是浮点型。</li></ul><h4 id="list-append-无返回值"><a href="#list-append-无返回值" class="headerlink" title="list.append()无返回值"></a>list.append()无返回值</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>case1 = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(case1.append(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># list.append没有返回值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 还有clear, insert, sort, reverse, remove, extend</span></span><br></pre></td></tr></table></figure><p>所以<code>case = case.append(1)</code>这样的操作不可行</p><h4 id="列表是可变的"><a href="#列表是可变的" class="headerlink" title="列表是可变的"></a>列表是可变的</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> = [<span class="number">9</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="keyword">case</span>:</span><br><span class="line">   <span class="keyword">if</span> i % <span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">     <span class="keyword">case</span>.remove(i)</span><br><span class="line">     </span><br><span class="line"><span class="built_in">print</span>(<span class="keyword">case</span>)</span><br><span class="line"></span><br><span class="line">&gt;&gt; [<span class="number">9</span>, <span class="number">8</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>]</span><br></pre></td></tr></table></figure><p>因为列表是可变对象，当第一个8被删除后，第二个8补上了前面的位置，自然而然就被跳过了</p><p>修改</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> = [<span class="number">9</span>, <span class="number">8</span>, <span class="number">8</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>]</span><br><span class="line">case1 = [x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="keyword">case</span> <span class="keyword">if</span> x%<span class="number">2</span> != <span class="number">0</span>]</span><br></pre></td></tr></table></figure><h4 id="字符串常量用空格连接"><a href="#字符串常量用空格连接" class="headerlink" title="字符串常量用空格连接"></a>字符串常量用空格连接</h4><p>表示字符串合并</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">case</span> = <span class="string">&#x27;a&#x27;</span> <span class="string">&#x27;b&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="keyword">case</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ab</span></span><br></pre></td></tr></table></figure><h4 id="tuple只有一个元素要在末尾加逗号"><a href="#tuple只有一个元素要在末尾加逗号" class="headerlink" title="tuple只有一个元素要在末尾加逗号"></a>tuple只有一个元素要在末尾加逗号</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>((<span class="string">&#x27;bilibili&#x27;</span>), <span class="built_in">tuple</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">isinstance</span>((<span class="string">&#x27;bilibili&#x27;</span>,), <span class="built_in">tuple</span>)</span><br><span class="line"></span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="literal">True</span></span><br><span class="line"></span><br><span class="line">a = (<span class="string">&#x27;bilibili&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> a:</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br><span class="line">b</span><br><span class="line">i</span><br><span class="line">l</span><br><span class="line">i</span><br><span class="line">b</span><br><span class="line">i</span><br><span class="line">l</span><br><span class="line">i</span><br><span class="line"></span><br><span class="line">b = (<span class="string">&#x27;bilibli&#x27;</span>,)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> b:</span><br><span class="line">    <span class="built_in">print</span>(i)</span><br><span class="line">bilibli</span><br></pre></td></tr></table></figure><h4 id="if-else表达式优先级高于逗号"><a href="#if-else表达式优先级高于逗号" class="headerlink" title="if-else表达式优先级高于逗号"></a>if-else表达式优先级高于逗号</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x, y = (<span class="number">10</span>, <span class="number">10</span>) <span class="keyword">if</span> <span class="literal">True</span> <span class="keyword">else</span> <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">(<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y</span><br><span class="line"><span class="literal">None</span></span><br></pre></td></tr></table></figure><h4 id="使用enumerate遍历："><a href="#使用enumerate遍历：" class="headerlink" title="使用enumerate遍历："></a>使用enumerate遍历：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data = [<span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>]</span><br><span class="line"><span class="keyword">for</span> idx, num <span class="keyword">in</span> <span class="built_in">enumerate</span>(data):</span><br><span class="line">    <span class="keyword">if</span> num % <span class="number">2</span>:</span><br><span class="line">        data[idx] = <span class="number">0</span></span><br><span class="line"><span class="built_in">print</span>(data)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[<span class="number">0</span>, <span class="number">4</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br></pre></td></tr></table></figure><h4 id="字典的get方法"><a href="#字典的get方法" class="headerlink" title="字典的get方法"></a>字典的get方法</h4><p>在工程文件中经常会注意到使用get方法，避免因键不存在而引起的程序崩溃，若索引不到，将返回在第二个位置定义的参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data = &#123;<span class="string">&quot;name&quot;</span> : <span class="string">&quot;sds&quot;</span>, <span class="string">&quot;age&quot;</span> : <span class="string">&quot;18&quot;</span>&#125;</span><br><span class="line">uid = data.get(<span class="string">&quot;uid&quot;</span>, <span class="string">&quot;6688&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(uid)</span><br><span class="line"></span><br><span class="line"><span class="number">6688</span></span><br></pre></td></tr></table></figure><h4 id="f-string新格式化方法"><a href="#f-string新格式化方法" class="headerlink" title="f-string新格式化方法"></a>f-string新格式化方法</h4><p>Python3.6开始支持的新的格式化操作，相比以前更简洁方便。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">i = <span class="number">9</span></span><br><span class="line">data = <span class="string">f&quot;<span class="subst">&#123;i&#125;</span> * <span class="subst">&#123;i&#125;</span> = <span class="subst">&#123;i * i&#125;</span>&quot;</span></span><br><span class="line"><span class="built_in">print</span>(data)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">9</span> * <span class="number">9</span> = <span class="number">81</span></span><br></pre></td></tr></table></figure><p>我们也常常这样</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">&#x27;xhm&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;hello,&#x27;</span>+name+<span class="string">&#x27;!&#x27;</span>)</span><br></pre></td></tr></table></figure><p>改为</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;hello,<span class="subst">&#123;name&#125;</span>!&#x27;</span>)</span><br><span class="line"><span class="comment"># hello,xhm!</span></span><br></pre></td></tr></table></figure><h4 id="合并两个字典"><a href="#合并两个字典" class="headerlink" title="合并两个字典"></a>合并两个字典</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data_1 = &#123;<span class="string">&quot;name&quot;</span> : <span class="string">&quot;sds&quot;</span>, <span class="string">&quot;age&quot;</span> : <span class="string">&quot;18&quot;</span>&#125;</span><br><span class="line">data_2 = &#123;<span class="string">&quot;name&quot;</span> : <span class="string">&quot;sds&quot;</span>, <span class="string">&quot;uid&quot;</span> : <span class="string">&quot;6688&quot;</span>&#125;</span><br><span class="line">out_data = &#123;**data_1, **data_2&#125;</span><br><span class="line"><span class="built_in">print</span>(out_data)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;sds&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="string">&#x27;18&#x27;</span>, <span class="string">&#x27;uid&#x27;</span>: <span class="string">&#x27;6688&#x27;</span>&#125;</span><br></pre></td></tr></table></figure><h4 id="判断某对象是否为某些值"><a href="#判断某对象是否为某些值" class="headerlink" title="判断某对象是否为某些值"></a>判断某对象是否为某些值</h4><p>如果需要在if中将某对象与多个其他对象进行对比判断，你可能会进行如下定义</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data = <span class="string">&quot;a&quot;</span></span><br><span class="line"><span class="keyword">if</span> data == <span class="string">&quot;a&quot;</span> <span class="keyword">or</span> data == <span class="string">&quot;b&quot;</span> <span class="keyword">or</span> data == <span class="string">&quot;c&quot;</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;HHH&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>HHH</span><br></pre></td></tr></table></figure><p>简化修改为</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">datas = [<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>]</span><br><span class="line">data = <span class="string">&quot;a&quot;</span></span><br><span class="line"><span class="keyword">if</span> data <span class="keyword">in</span> datas:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;HHH&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>HHH</span><br></pre></td></tr></table></figure><h4 id="注意-和-的区别"><a href="#注意-和-的区别" class="headerlink" title="注意^和**的区别"></a>注意^和**的区别</h4><p>按位异或  和   次幂</p><h4 id="写文件时请用with"><a href="#写文件时请用with" class="headerlink" title="写文件时请用with"></a>写文件时请用with</h4><p>当写入出错时会报错，文件会关闭</p><h4 id="数字中的下划线"><a href="#数字中的下划线" class="headerlink" title="数字中的下划线"></a>数字中的下划线</h4><p><code>x=10000000</code>和<code>x=10_000_000</code>等价，但是后者明显更加清晰</p><h4 id="没穿衣服的元组"><a href="#没穿衣服的元组" class="headerlink" title="没穿衣服的元组"></a>没穿衣服的元组</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">1</span>,<span class="number">2</span></span><br><span class="line">d1 = x[<span class="number">0</span>]</span><br><span class="line">d2 = x[<span class="number">1</span>]</span><br></pre></td></tr></table></figure><h4 id="使用isinstance代替-x3D-x3D-号检查类型"><a href="#使用isinstance代替-x3D-x3D-号检查类型" class="headerlink" title="使用isinstance代替&#x3D;&#x3D;号检查类型"></a>使用isinstance代替&#x3D;&#x3D;号检查类型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">type</span>(name) == <span class="built_in">tuple</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">isinstance</span>(name, <span class="built_in">tuple</span>)</span><br></pre></td></tr></table></figure><h4 id="b-a-x3D-a-b快速值交换"><a href="#b-a-x3D-a-b快速值交换" class="headerlink" title="b,a  &#x3D; a,b快速值交换"></a>b,a  &#x3D; a,b快速值交换</h4>]]></content>
      
      
      
        <tags>
            
            <tag> python小知识 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python三剑客及一些常用函数</title>
      <link href="/2023/01/04/python%E4%B8%89%E5%89%91%E5%AE%A2%E5%8F%8A%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/"/>
      <url>/2023/01/04/python%E4%B8%89%E5%89%91%E5%AE%A2%E5%8F%8A%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<h3 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h3><h4 id="str"><a href="#str" class="headerlink" title="str"></a>str</h4><ol><li>string.count(str, beg&#x3D;0, end&#x3D;len(string))    返回 str 在 string 里面出现的次数，如果 beg 或者 end 指定则返回指定范围内 str 出现的次数</li><li>string.find(str, beg&#x3D;0, end&#x3D;len(string))       检测str是否包含在string中，如果beg和end指定范围，则检查是否包含在指定范围内，如果是返回开始的索引值，否则返回-1</li><li>string.format()</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="string">&quot;&#123;&#125; &#123;&#125;&quot;</span>.<span class="built_in">format</span>(<span class="string">&quot;hello&quot;</span>, <span class="string">&quot;world&quot;</span>)    <span class="comment"># 不设置指定位置，按默认顺序</span></span><br><span class="line"><span class="string">&#x27;hello world&#x27;</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">&quot;&#123;0&#125; &#123;1&#125;&quot;</span>.<span class="built_in">format</span>(<span class="string">&quot;hello&quot;</span>, <span class="string">&quot;world&quot;</span>)  <span class="comment"># 设置指定位置</span></span><br><span class="line"><span class="string">&#x27;hello world&#x27;</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">&quot;&#123;1&#125; &#123;0&#125; &#123;1&#125;&quot;</span>.<span class="built_in">format</span>(<span class="string">&quot;hello&quot;</span>, <span class="string">&quot;world&quot;</span>)  <span class="comment"># 设置指定位置</span></span><br><span class="line"><span class="string">&#x27;world hello world&#x27;</span></span><br></pre></td></tr></table></figure><p>也可以设置参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;网站名：&#123;name&#125;, 地址 &#123;url&#125;&quot;</span>.<span class="built_in">format</span>(name=<span class="string">&quot;菜鸟教程&quot;</span>, url=<span class="string">&quot;www.runoob.com&quot;</span>))</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 通过字典设置参数</span></span><br><span class="line">site = &#123;<span class="string">&quot;name&quot;</span>: <span class="string">&quot;菜鸟教程&quot;</span>, <span class="string">&quot;url&quot;</span>: <span class="string">&quot;www.runoob.com&quot;</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;网站名：&#123;name&#125;, 地址 &#123;url&#125;&quot;</span>.<span class="built_in">format</span>(**site))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过列表索引设置参数</span></span><br><span class="line">my_list = [<span class="string">&#x27;菜鸟教程&#x27;</span>, <span class="string">&#x27;www.runoob.com&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;网站名：&#123;0[0]&#125;, 地址 &#123;0[1]&#125;&quot;</span>.<span class="built_in">format</span>(my_list))  <span class="comment"># &quot;0&quot; 是必须的</span></span><br></pre></td></tr></table></figure><p>也可以向 <strong>str.format()</strong> 传入对象：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AssignValue</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, value</span>):</span><br><span class="line">        self.value = value</span><br><span class="line">my_value = AssignValue(<span class="number">6</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;value 为: &#123;0.value&#125;&#x27;</span>.<span class="built_in">format</span>(my_value))  <span class="comment"># &quot;0&quot; 是可选的</span></span><br></pre></td></tr></table></figure><p>格式化数字的方法</p><p><img src="https://haoming2003.oss-cn-hangzhou.aliyuncs.com/image-20230102114624443.png" alt="image-20230102114624443"></p><p><code>d</code> means expecting an int:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">&quot;&#123;:d&#125;&quot;</span>.<span class="built_in">format</span>(<span class="number">3</span>)</span><br><span class="line"><span class="string">&#x27;3&#x27;</span></span><br></pre></td></tr></table></figure><p><code>2d</code> means formats to 2 characters using padding (whitespace by default)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">&quot;&#123;:2d&#125;&quot;</span>.<span class="built_in">format</span>(<span class="number">3</span>)</span><br><span class="line"><span class="string">&#x27; 3&#x27;</span></span><br></pre></td></tr></table></figure><p><code>0&gt;</code> means using <code>0</code> as padding, and right adjust the result:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="string">&quot;&#123;:0&gt;2d&#125;&quot;</span>.<span class="built_in">format</span>(<span class="number">3</span>)</span><br><span class="line"><span class="string">&#x27;03&#x27;</span></span><br></pre></td></tr></table></figure><ol start="4"><li>string.join(seq)  以 string 作为分隔符，将 seq 中所有的元素(的字符串表示)<strong>合并为一个新的字符串</strong></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new_seq = <span class="string">&#x27; &#x27;</span>.join(seq)</span><br></pre></td></tr></table></figure><ol start="5"><li>string.replace(str1, str2, num&#x3D;string.count(str1))   把string中<strong>str1替换为str2</strong>，如果num指定，则替换不超过num次</li><li>string.split(str&#x3D;””, num&#x3D;string.count(str))  以 str 为分隔符<strong>切片 string为列表</strong>，如果 num 有指定值，则仅分隔 <strong>num+1</strong> 个子字符串</li><li>string.strip([obj])    在 string 上执行 lstrip()和 rstrip()</li></ol><h4 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h4><ol><li>list(seq)     将元组转换成列表</li><li>list.append()    在列表末尾添加新的对象</li><li>list.count()     统计某个元素在列表中出现的次数</li><li>list.extend(seq) 在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表）</li></ol><h4 id="元组"><a href="#元组" class="headerlink" title="元组"></a>元组</h4><p>tuple(iterable)   将可迭代系列转换为元组。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>list1= [<span class="string">&#x27;Google&#x27;</span>, <span class="string">&#x27;Taobao&#x27;</span>, <span class="string">&#x27;Runoob&#x27;</span>, <span class="string">&#x27;Baidu&#x27;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tuple1=<span class="built_in">tuple</span>(list1)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tuple1</span><br><span class="line">(<span class="string">&#x27;Google&#x27;</span>, <span class="string">&#x27;Taobao&#x27;</span>, <span class="string">&#x27;Runoob&#x27;</span>, <span class="string">&#x27;Baidu&#x27;</span>)</span><br></pre></td></tr></table></figure><p>元组不变是指     <strong>元组所指向的内存中的内容不可变</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>tup = (<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;u&#x27;</span>, <span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;o&#x27;</span>, <span class="string">&#x27;o&#x27;</span>, <span class="string">&#x27;b&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tup[<span class="number">0</span>] = <span class="string">&#x27;g&#x27;</span>     <span class="comment"># 不支持修改元素</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">TypeError: <span class="string">&#x27;tuple&#x27;</span> <span class="built_in">object</span> does <span class="keyword">not</span> support item assignment</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">id</span>(tup)     <span class="comment"># 查看内存地址</span></span><br><span class="line"><span class="number">4440687904</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tup = (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">id</span>(tup)</span><br><span class="line"><span class="number">4441088800</span>    <span class="comment"># 内存地址不一样了</span></span><br></pre></td></tr></table></figure><h4 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">d=&#123;<span class="number">1</span>:<span class="string">&quot;a&quot;</span>,<span class="number">2</span>:<span class="string">&quot;b&quot;</span>,<span class="number">3</span>:<span class="string">&quot;c&quot;</span>&#125;</span><br><span class="line">result=[]</span><br><span class="line"><span class="keyword">for</span> k,v <span class="keyword">in</span> d.items():</span><br><span class="line">    result.append(k)</span><br><span class="line">    result.append(v)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line">&gt;&gt; [<span class="number">1</span>, <span class="string">&#x27;a&#x27;</span>, <span class="number">2</span>, <span class="string">&#x27;b&#x27;</span>, <span class="number">3</span>, <span class="string">&#x27;c&#x27;</span>]</span><br></pre></td></tr></table></figure><h4 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h4><p>集合运算</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">data_1 = &#123;<span class="string">&#x27;Mathematics&#x27;</span>, <span class="string">&#x27;Chinese&#x27;</span>, <span class="string">&#x27;English&#x27;</span>, <span class="string">&#x27;Physics&#x27;</span>, <span class="string">&#x27;Chemistry&#x27;</span>, <span class="string">&#x27;Biology&#x27;</span>&#125;</span><br><span class="line">data_2 = &#123;<span class="string">&#x27;Mathematics&#x27;</span>, <span class="string">&#x27;Chinese&#x27;</span>, <span class="string">&#x27;English&#x27;</span>, <span class="string">&#x27;Politics&#x27;</span>, <span class="string">&#x27;Geography&#x27;</span>, <span class="string">&#x27;History&#x27;</span>&#125;</span><br><span class="line"><span class="comment"># 交集</span></span><br><span class="line">data_1 &amp; data_2</span><br><span class="line"><span class="comment"># 并集</span></span><br><span class="line">data_1 | data_2</span><br><span class="line"><span class="comment"># 差集</span></span><br><span class="line">data_1 - data_2</span><br><span class="line"><span class="comment"># 异或（不同时包含于两集合中的数据）</span></span><br><span class="line">data_1 ^ data_2</span><br></pre></td></tr></table></figure><h4 id="sorted"><a href="#sorted" class="headerlink" title="sorted()"></a>sorted()</h4><p>如果你需要对可迭代对象进行排序，比如列表、元组、字典，首先以列表为例子，可以直接使用内置函数sorted完成任务</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data = [-<span class="number">1</span>, -<span class="number">10</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">5</span>]</span><br><span class="line">new_data = <span class="built_in">sorted</span>(data)</span><br><span class="line"><span class="comment"># new_data = sorted(data, reverse=True)降序</span></span><br><span class="line"><span class="built_in">print</span>(new_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># [-10, -1, 0, 5, 9]</span></span><br></pre></td></tr></table></figure><p>对元组使用之后输出类型会变成列表</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data = (-<span class="number">1</span>, -<span class="number">10</span>, <span class="number">0</span>, <span class="number">9</span>, <span class="number">5</span>)</span><br><span class="line">new_data = <span class="built_in">sorted</span>(data, reverse=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(new_data)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[<span class="number">9</span>, <span class="number">5</span>, <span class="number">0</span>, -<span class="number">1</span>, -<span class="number">10</span>]</span><br></pre></td></tr></table></figure><p>字典</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">data = [</span><br><span class="line">    &#123;<span class="string">&quot;name&quot;</span> : <span class="string">&quot;jia&quot;</span>, <span class="string">&quot;age&quot;</span> : <span class="number">18</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;name&quot;</span> : <span class="string">&quot;yi&quot;</span>, <span class="string">&quot;age&quot;</span> : <span class="number">60</span>&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;name&quot;</span> : <span class="string">&quot;bing&quot;</span>, <span class="string">&quot;age&quot;</span> : <span class="number">20</span>&#125;</span><br><span class="line">]</span><br><span class="line">new_data = <span class="built_in">sorted</span>(data, key=<span class="keyword">lambda</span> x: x[<span class="string">&quot;age&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(new_data)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[&#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;jia&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">18</span>&#125;, &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;bing&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">20</span>&#125;, &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;yi&#x27;</span>, <span class="string">&#x27;age&#x27;</span>: <span class="number">60</span>&#125;]</span><br></pre></td></tr></table></figure><h3 id="pandas"><a href="#pandas" class="headerlink" title="pandas"></a>pandas</h3><h4 id="get-dummies"><a href="#get-dummies" class="headerlink" title="get_dummies()"></a>get_dummies()</h4><p>pandas实现one hot encode的方式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pandas.get_dummies(data, prefix=<span class="literal">None</span>, prefix_sep=<span class="string">&#x27;_&#x27;</span>, dummy_na=<span class="literal">False</span>, columns=<span class="literal">None</span>, sparse=<span class="literal">False</span>, drop_first=<span class="literal">False</span>)[source]</span><br></pre></td></tr></table></figure><p>例子</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.DataFrame([</span><br><span class="line">    [<span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;A&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;B&#x27;</span>],</span><br><span class="line">    [<span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;A&#x27;</span>]</span><br><span class="line">])</span><br><span class="line">df.columns = [<span class="string">&#x27;color&#x27;</span>, <span class="string">&#x27;class&#x27;</span>]</span><br><span class="line">df = pd.get_dummies(df)</span><br></pre></td></tr></table></figure><p>get_dummies前</p><table><thead><tr><th></th><th>color</th><th>class</th></tr></thead><tbody><tr><td>0</td><td>green</td><td>A</td></tr><tr><td>1</td><td>red</td><td>B</td></tr><tr><td>2</td><td>blue</td><td>A</td></tr></tbody></table><p>get_dummies后</p><table><thead><tr><th align="left"></th><th align="center">color_blue</th><th align="center">color_green</th><th align="center">color_red</th><th align="center">color_A</th><th align="center">color_B</th></tr></thead><tbody><tr><td align="left">0</td><td align="center">0</td><td align="center">1</td><td align="center">0</td><td align="center">1</td><td align="center">0</td></tr><tr><td align="left">1</td><td align="center">0</td><td align="center">0</td><td align="center">1</td><td align="center">0</td><td align="center">1</td></tr><tr><td align="left">2</td><td align="center">1</td><td align="center">0</td><td align="center">0</td><td align="center">1</td><td align="center">0</td></tr></tbody></table><p>可以对指定列进行get_dummies</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.get_dummies(df.color)</span><br></pre></td></tr></table></figure><table><thead><tr><th></th><th>blue</th><th>green</th><th>red</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>1</td><td>0</td></tr><tr><td>1</td><td>0</td><td>0</td><td>1</td></tr><tr><td>2</td><td>1</td><td>0</td><td>0</td></tr></tbody></table><p>将指定列进行get_dummies 后合并到元数据中</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = df.join(pd.get_dummies(df.color))</span><br></pre></td></tr></table></figure><table><thead><tr><th></th><th>color</th><th>class</th><th>blue</th><th>green</th><th>red</th></tr></thead><tbody><tr><td>0</td><td>green</td><td>A</td><td>0</td><td>1</td><td>0</td></tr><tr><td>1</td><td>red</td><td>B</td><td>0</td><td>0</td><td>1</td></tr><tr><td>2</td><td>blue</td><td>A</td><td>1</td><td>0</td><td>0</td></tr></tbody></table><h4 id="concat"><a href="#concat" class="headerlink" title="concat()"></a>concat()</h4><p><strong>连接内容 objs</strong></p><p>需要连接的数据，可以是多个 DataFrame 或者 Series。必传参数。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Series 或 DataFrame 对象的序列或映射</span><br><span class="line">s1 = pd.Series([&#x27;a&#x27;, &#x27;b&#x27;])</span><br><span class="line">s2 = pd.Series([&#x27;c&#x27;, &#x27;d&#x27;])</span><br><span class="line">pd.concat([s1, s2])</span><br><span class="line"></span><br><span class="line"># df</span><br><span class="line">df1 = pd.DataFrame([[&#x27;a&#x27;, 1], [&#x27;b&#x27;, 2]], columns=[&#x27;letter&#x27;, &#x27;number&#x27;])</span><br><span class="line">df2 = pd.DataFrame([[&#x27;c&#x27;, 3], [&#x27;d&#x27;, 4]], columns=[&#x27;letter&#x27;, &#x27;number&#x27;])</span><br><span class="line">pd.concat([df1, df2])</span><br></pre></td></tr></table></figure><p><strong>轴方向 axis</strong></p><p>连接轴的方法，默认是 0，按行连接，追加在行后边，为 1 时追加到列后边。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># &#123;0/’index’, 1/’columns’&#125;, default 0</span><br><span class="line">pd.concat([df1, df4], axis=1) # 按列</span><br></pre></td></tr></table></figure><p><strong>合并方式 join</strong></p><p>其他轴上的数据是按交集（inner）还是并集（outer）进行合并。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># &#123;‘inner’, ‘outer’&#125;, default ‘outer’</span><br><span class="line">pd.concat([df1, df3], join=&quot;inner&quot;) # 按交集</span><br></pre></td></tr></table></figure><p><strong>保留索引 ignore_index</strong></p><p>是否保留原表索引，默认保留，为 True 会自动增加自然索引。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># bool, default False</span><br><span class="line">pd.concat([df1, df3], ignore_index=True) # 不保留索引</span><br></pre></td></tr></table></figure><h4 id="dropna"><a href="#dropna" class="headerlink" title="dropna()"></a>dropna()</h4><p>DataFrame.dropna(axis&#x3D;0, how&#x3D;’any’, thresh&#x3D;None, subset&#x3D;None, inplace&#x3D;False)</p><p>axis:</p><ul><li>axis&#x3D;0: 删除包含缺失值的行</li><li>axis&#x3D;1: 删除包含缺失值的列</li></ul><p>how: 与axis配合使用</p><ul><li>how&#x3D;‘any’ :只要有缺失值出现，就删除该行货列</li><li>how&#x3D;‘all’: 所有的值都缺失，才删除行或列</li></ul><p>thresh： axis中至少有thresh个非缺失值，否则删除<br>比如 axis&#x3D;0，thresh&#x3D;10：标识如果该行中非缺失值的数量小于10，将删除改行</p><p>subset: list<br>在哪些列中查看是否有缺失值</p><p>inplace: 是否在原数据上操作。如果为真，返回None否则返回新的copy，去掉了缺失值</p><h4 id="drop"><a href="#drop" class="headerlink" title="drop()"></a>drop()</h4><p>DataFrame.drop(labels&#x3D;None, axis&#x3D;0, index&#x3D;None, columns&#x3D;None, level&#x3D;None, inplace&#x3D;False, errors&#x3D;’raise’)</p><ul><li>labels: 要删除行或列的列表</li><li>axis: 0 行 ；1 列</li></ul><h4 id="fillna"><a href="#fillna" class="headerlink" title="fillna()"></a>fillna()</h4><p>DataFrame.fillna(value&#x3D;None, method&#x3D;None, axis&#x3D;None, inplace&#x3D;False, limit&#x3D;None, downcast&#x3D;None, **kwargs)</p><ul><li><p>value: scalar, dict, Series, or DataFrame<br>dict 可以指定每一行或列用什么值填充</p></li><li><p>method： {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default None<br>在列上操作</p><ul><li>ffill &#x2F; pad: 使用前一个值来填充缺失值</li><li>backfill &#x2F; bfill :使用后一个值来填充缺失值</li></ul></li><li><p>limit 填充的缺失值个数限制。应该不怎么用</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用0代替所有的缺失值</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df.fillna(<span class="number">0</span>)</span><br><span class="line">    A   B   C   D</span><br><span class="line"><span class="number">0</span>   <span class="number">0.0</span> <span class="number">2.0</span> <span class="number">0.0</span> <span class="number">0</span></span><br><span class="line"><span class="number">1</span>   <span class="number">3.0</span> <span class="number">4.0</span> <span class="number">0.0</span> <span class="number">1</span></span><br><span class="line"><span class="number">2</span>   <span class="number">0.0</span> <span class="number">0.0</span> <span class="number">0.0</span> <span class="number">5</span></span><br><span class="line"><span class="number">3</span>   <span class="number">0.0</span> <span class="number">3.0</span> <span class="number">0.0</span> <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用后边或前边的值填充缺失值</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>df.fillna(method=<span class="string">&#x27;ffill&#x27;</span>)</span><br><span class="line">    A   B   C   D</span><br><span class="line"><span class="number">0</span>   NaN <span class="number">2.0</span> NaN <span class="number">0</span></span><br><span class="line"><span class="number">1</span>   <span class="number">3.0</span> <span class="number">4.0</span> NaN <span class="number">1</span></span><br><span class="line"><span class="number">2</span>   <span class="number">3.0</span> <span class="number">4.0</span> NaN <span class="number">5</span></span><br><span class="line"><span class="number">3</span>   <span class="number">3.0</span> <span class="number">3.0</span> NaN <span class="number">4</span></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;df.fillna(method=<span class="string">&#x27;bfill&#x27;</span>)</span><br><span class="line">     ABCD</span><br><span class="line"><span class="number">0</span><span class="number">3.0</span><span class="number">2.0</span>NaN<span class="number">0</span></span><br><span class="line"><span class="number">1</span><span class="number">3.0</span><span class="number">4.0</span>NaN<span class="number">1</span></span><br><span class="line"><span class="number">2</span>NaN<span class="number">3.0</span>NaN<span class="number">5</span></span><br><span class="line"><span class="number">3</span>NaN<span class="number">3.0</span>NaN<span class="number">4</span></span><br></pre></td></tr></table></figure><h4 id="csv操作"><a href="#csv操作" class="headerlink" title="csv操作"></a>csv操作</h4><ol><li>读csv不要索引</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = pd.read_csv(<span class="string">&quot;filename.csv&quot;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>,index_col=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><ol start="2"><li>写csv不要索引</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.to_csv(<span class="string">&quot;xxx.csv&quot;</span>,index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><ol start="3"><li>删除有空值的行</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df1 = df.dropna(subset=[<span class="string">&#x27;列名&#x27;</span>])</span><br></pre></td></tr></table></figure><ol start="4"><li>先把带有时间的列转为date_time格式，再进行排序。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df1[<span class="string">&#x27;time&#x27;</span>] = pd.to_datetime(df1[<span class="string">&#x27;time&#x27;</span>])</span><br><span class="line">df1.sort_values(<span class="string">&#x27;time&#x27;</span>, inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>inplace代表是否更改数据，默认是False，要保存结果的话需要inplace&#x3D;True。</p><ol start="5"><li>增加一列并赋值</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;xxx number&#x27;</span>] = <span class="number">1</span></span><br></pre></td></tr></table></figure><ol start="6"><li>插入列</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df1.insert(<span class="number">3</span>, <span class="string">&#x27;users number&#x27;</span>, df2[<span class="string">&#x27;users number&#x27;</span>])</span><br><span class="line">//df.insert(插入到哪一列, <span class="string">&#x27;列名&#x27;</span>, another_df[<span class="string">&#x27;需要被插入的那一列&#x27;</span>])</span><br></pre></td></tr></table></figure><ol start="7"><li>Pandas sample()用于从DataFrame中随机选择行和列。</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DataFrame.sample(n=<span class="literal">None</span>, frac=<span class="literal">None</span>, replace=<span class="literal">False</span>, weights=<span class="literal">None</span>, random_state=<span class="literal">None</span>, axis=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p> 参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">n：这是一个可选参数, 由整数值组成, 并定义生成的随机行数。</span><br><span class="line">frac：它也是一个可选参数, 由浮点值组成, 并返回浮点值*数据帧值的长度。不能与参数n一起使用。</span><br><span class="line">replace：由布尔值组成。如果为true, 则返回带有替换的样本。替换的默认值为false。</span><br><span class="line">权重：它也是一个可选参数, 由类似于<span class="built_in">str</span>或ndarray的参数组成。默认值”无”将导致相等的概率加权。</span><br><span class="line">如果正在通过系列赛；它将与索引上的目标对象对齐。在采样对象中找不到的权重索引值将被忽略, 而在采样对象中没有权重的索引值将被分配零权重。</span><br><span class="line">如果在轴= <span class="number">0</span>时正在传递DataFrame, 则返回<span class="number">0</span>。它将接受列的名称。</span><br><span class="line">如果权重是系列；然后, 权重必须与被采样轴的长度相同。</span><br><span class="line">如果权重不等于<span class="number">1</span>；它将被标准化为<span class="number">1</span>的总和。</span><br><span class="line">权重列中的缺失值被视为零。</span><br><span class="line">权重栏中不允许无穷大。</span><br><span class="line">random_state：它也是一个可选参数, 由整数或numpy.random.RandomState组成。如果值为<span class="built_in">int</span>, 则为随机数生成器或numpy RandomState对象设置种子。</span><br><span class="line">axis：它也是由整数或字符串值组成的可选参数。 <span class="number">0</span>或”行”和<span class="number">1</span>或”列”。</span><br></pre></td></tr></table></figure><ol start="8"><li>通过.fillna()填充空值。</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">inputs = inputs.fillna(inputs.mean())</span><br></pre></td></tr></table></figure><h4 id="pandas按列遍历Dataframe"><a href="#pandas按列遍历Dataframe" class="headerlink" title="pandas按列遍历Dataframe"></a>pandas按列遍历Dataframe</h4><ul><li>iterrows(): 按行遍历，将DataFrame的每一行迭代为(index, Series)对，可以通过row[name]对元素进行访问。</li><li>itertuples(): 按行遍历，将DataFrame的每一行迭代为元祖，可以通过row[name]对元素进行访问，比iterrows()效率高。</li><li>iteritems():按列遍历，将DataFrame的每一列迭代为(列名, Series)对，可以通过row[index]对元素进行访问。</li></ul><p>示例数据</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">inp = [&#123;<span class="string">&#x27;c1&#x27;</span>:<span class="number">10</span>, <span class="string">&#x27;c2&#x27;</span>:<span class="number">100</span>&#125;, &#123;<span class="string">&#x27;c1&#x27;</span>:<span class="number">11</span>, <span class="string">&#x27;c2&#x27;</span>:<span class="number">110</span>&#125;, &#123;<span class="string">&#x27;c1&#x27;</span>:<span class="number">12</span>, <span class="string">&#x27;c2&#x27;</span>:<span class="number">123</span>&#125;]</span><br><span class="line">df = pd.DataFrame(inp)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(df)</span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20190227143422984.png" alt="在这里插入图片描述"></p><p><strong>按行遍历iterrows():</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> index, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">    <span class="built_in">print</span>(index) <span class="comment"># 输出每行的索引值</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20190227143612870.png" alt="在这里插入图片描述"></p><p>row[‘name’]</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于每一行，通过列名name访问对应的元素</span></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">    <span class="built_in">print</span>(row[<span class="string">&#x27;c1&#x27;</span>], row[<span class="string">&#x27;c2&#x27;</span>]) <span class="comment"># 输出每一行</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20190227143716567.png" alt="在这里插入图片描述"></p><p><strong>按行遍历itertuples():</strong><br>getattr(row, ‘name’)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> df.itertuples():</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">getattr</span>(row, <span class="string">&#x27;c1&#x27;</span>), <span class="built_in">getattr</span>(row, <span class="string">&#x27;c2&#x27;</span>)) <span class="comment"># 输出每一行</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20190227143835738.png" alt="在这里插入图片描述"></p><p><strong>按列遍历iteritems():</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> index, row <span class="keyword">in</span> df.iteritems():</span><br><span class="line">    <span class="built_in">print</span>(index) <span class="comment"># 输出列名</span></span><br><span class="line">    </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>c1<br>c2</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> df.iteritems():</span><br><span class="line">    <span class="built_in">print</span>(row[<span class="number">0</span>], row[<span class="number">1</span>], row[<span class="number">2</span>]) <span class="comment"># 输出各列</span></span><br></pre></td></tr></table></figure><p><img src="https://img-blog.csdnimg.cn/20190227144037269.png" alt="在这里插入图片描述"></p><h3 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h3><h4 id="axis理解"><a href="#axis理解" class="headerlink" title="axis理解"></a>axis理解</h4><p>参考： <a href="https://zhuanlan.zhihu.com/p/31275071">https://zhuanlan.zhihu.com/p/31275071</a></p><p>简单来说就是：</p><ul><li><strong>Axis就是数组层级</strong></li><li><strong>设axis&#x3D;i，则Numpy沿着第i个下标变化的方向进行操作</strong></li></ul><h4 id="reshape"><a href="#reshape" class="headerlink" title="reshape()"></a>reshape()</h4><p>重新定义矩阵的形状</p><p><strong>相当于pytorch中的view()</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">v1 = torch.<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">16</span>)</span><br><span class="line">v2 = v1.view(<span class="number">4</span>,<span class="number">4</span>)</span><br></pre></td></tr></table></figure><p>参数使用-1，<strong>view中一个参数定为-1，代表动态调整这个维度上的元素个数，以保证元素的总数不变</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">v1 = torch.<span class="built_in">range</span>(<span class="number">1</span>,<span class="number">16</span>)</span><br><span class="line">v2 = v1.view(-<span class="number">1</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 代码效果同上</span></span><br></pre></td></tr></table></figure><h4 id="np-r-和-np-c"><a href="#np-r-和-np-c" class="headerlink" title="np.r_ 和 np.c_"></a>np.r_ 和 np.c_</h4><p>np.r_是按列连接两个<a href="https://so.csdn.net/so/search?q=%E7%9F%A9%E9%98%B5&spm=1001.2101.3001.7020">矩阵</a>，就是把两矩阵上下相加，要求列数相等。</p><p>np.c_是按行连接两个矩阵，就是把两矩阵左右相加，要求行数相等。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">a = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>]])</span><br><span class="line">b=np.array([[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>],[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]])</span><br><span class="line"> </span><br><span class="line">&gt;&gt;a</span><br><span class="line">Out[<span class="number">4</span>]: </span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]])</span><br><span class="line"> </span><br><span class="line">&gt;&gt;b</span><br><span class="line">Out[<span class="number">5</span>]: </span><br><span class="line">array([[<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">       [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]])</span><br><span class="line"> </span><br><span class="line">c=np.c_[a,b]</span><br><span class="line"> </span><br><span class="line">&gt;&gt;c</span><br><span class="line">Out[<span class="number">7</span>]: </span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>],</span><br><span class="line">       [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]])</span><br></pre></td></tr></table></figure><h4 id="eye"><a href="#eye" class="headerlink" title="eye()"></a>eye()</h4><p>numpy.eye(N,M&#x3D;None,k&#x3D;0,dtype&#x3D;&lt;class ‘float’&gt;,order&#x3D;’C)</p><p>返回的是一个二维2的数组(N,M)，对角线的地方为1，其余的地方为0.</p><p>参数介绍：</p><p>（1）N:int型，表示的是输出的行数</p><p>（2）M：int型，可选项，输出的列数，如果没有就默认为N</p><p>（3）k：int型，可选项，对角线的下标，默认为0表示的是主对角线，负数表示的是低对角，正数表示的是高对角。</p><p>（4）dtype：数据的类型，可选项，返回的数据的数据类型</p><p>（5）order：{‘C’，‘F’}，可选项，也就是输出的数组的形式是按照C语言的行优先’C’，还是按照Fortran形式的列优先‘F’存储在内存中</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"> </span><br><span class="line">a=np.eye(<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"> </span><br><span class="line">a=np.eye(<span class="number">4</span>,k=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"> </span><br><span class="line">a=np.eye(<span class="number">4</span>,k=-<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"> </span><br><span class="line">a=np.eye(<span class="number">4</span>,k=-<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(a)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span>]]</span><br><span class="line">[[<span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]]</span><br><span class="line">[[<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span>]]</span><br><span class="line">[[<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span> <span class="number">0.</span>]]</span><br></pre></td></tr></table></figure><h5 id="深度学习高级用法"><a href="#深度学习高级用法" class="headerlink" title="深度学习高级用法"></a>深度学习高级用法</h5><p>将数组转化为 one-hot形式</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">labels = np.array([[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">0</span>],[<span class="number">1</span>]])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;label的大小:&#x27;</span>,labels.shape,<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#因为我们的类别是从0-2，所以这里是3个类</span></span><br><span class="line">a=np.eye(<span class="number">3</span>)[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;如果对应的类别号是1，那么转成one-hot的形式&quot;</span>,a,<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"> </span><br><span class="line">a=np.eye(<span class="number">3</span>)[<span class="number">2</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;如果对应的类别号是2，那么转成one-hot的形式&quot;</span>,a,<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"> </span><br><span class="line">a=np.eye(<span class="number">3</span>)[<span class="number">1</span>,<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;1转成one-hot的数组的第一个数字是：&quot;</span>,a,<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#这里和上面的结果的区别，注意!!!</span></span><br><span class="line">a=np.eye(<span class="number">3</span>)[[<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>]]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;如果对应的类别号是1,2,0,1，那么转成one-hot的形式\n&quot;</span>,a)</span><br><span class="line"> </span><br><span class="line">res=np.eye(<span class="number">3</span>)[labels.reshape(-<span class="number">1</span>)]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;labels转成one-hot形式的结果：\n&quot;</span>,res,<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;labels转化成one-hot后的大小：&quot;</span>,res.shape)</span><br></pre></td></tr></table></figure><p>结果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">labels的大小： (<span class="number">4</span>, <span class="number">1</span>) </span><br><span class="line"> </span><br><span class="line">如果对应的类别号是<span class="number">1</span>，那么转成one-hot的形式 [<span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span>] </span><br><span class="line"> </span><br><span class="line">如果对应的类别号是<span class="number">2</span>，那么转成one-hot的形式 [<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span>] </span><br><span class="line"> </span><br><span class="line"><span class="number">1</span>转成one-hot的数组的第一个数字是： <span class="number">0.0</span> </span><br><span class="line"> </span><br><span class="line">如果对应的类别号是<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>，那么转成one-hot的形式</span><br><span class="line"> [[<span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span>]]</span><br><span class="line">labels转成one-hot形式的结果：</span><br><span class="line"> [[<span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">0.</span> <span class="number">1.</span>]</span><br><span class="line"> [<span class="number">1.</span> <span class="number">0.</span> <span class="number">0.</span>]</span><br><span class="line"> [<span class="number">0.</span> <span class="number">1.</span> <span class="number">0.</span>]] </span><br><span class="line"> </span><br><span class="line">labels转化成one-hot后的大小： (<span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#注：</span></span><br><span class="line">label.reshape(-<span class="number">1</span>)</span><br><span class="line">--&gt;   array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>])变成了一维数组</span><br></pre></td></tr></table></figure><h4 id="identity"><a href="#identity" class="headerlink" title="identity()"></a>identity()</h4><p>与eye()的区别在于只能创建方阵</p><h4 id="np-linalg-norm求范数"><a href="#np-linalg-norm求范数" class="headerlink" title="np.linalg.norm求范数"></a>np.linalg.norm求范数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_norm=np.linalg.norm(x, <span class="built_in">ord</span>=<span class="literal">None</span>, axis=<span class="literal">None</span>, keepdims=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x = np.array([</span><br><span class="line">    [<span class="number">0</span>, <span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">    [<span class="number">1</span>, <span class="number">6</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="comment">#默认参数ord=None，axis=None，keepdims=False</span></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;默认参数(矩阵整体元素平方和开根号，不保留矩阵二维特性)：&quot;</span>,np.linalg.norm(x)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;矩阵整体元素平方和开根号，保留矩阵二维特性：&quot;</span>,np.linalg.norm(x,keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;矩阵每个行向量求向量的2范数：&quot;</span>,np.linalg.norm(x,axis=<span class="number">1</span>,keepdims=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;矩阵每个列向量求向量的2范数：&quot;</span>,np.linalg.norm(x,axis=<span class="number">0</span>,keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;矩阵1范数：&quot;</span>,np.linalg.norm(x,<span class="built_in">ord</span>=<span class="number">1</span>,keepdims=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;矩阵2范数：&quot;</span>,np.linalg.norm(x,<span class="built_in">ord</span>=<span class="number">2</span>,keepdims=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;矩阵∞范数：&quot;</span>,np.linalg.norm(x,<span class="built_in">ord</span>=np.inf,keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&quot;矩阵每个行向量求向量的1范数：&quot;</span>,np.linalg.norm(x,<span class="built_in">ord</span>=<span class="number">1</span>,axis=<span class="number">1</span>,keepdims=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><h4 id="squeeze"><a href="#squeeze" class="headerlink" title="squeeze()"></a>squeeze()</h4><p><strong>作用</strong>：从数组的形状中删除单维度条目，即把shape中为1的维度去掉,<strong>对非单维的维度不起作用</strong></p><p>np.squeeze(a, axis &#x3D; None)</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1）a表示输入的数组；</span><br><span class="line">2）axis用于指定需要删除的维度，但是指定的维度必须为单维度，否则将会报错；</span><br><span class="line">3）axis的取值可为None 或 int 或 tuple of ints, 可选。若axis为空，则删除所有单维度的条目；</span><br><span class="line">4）返回值：数组</span><br><span class="line">5) 不会修改原数组；</span><br></pre></td></tr></table></figure><p>eg:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.arange(10).reshape(1, 10)</span><br><span class="line"># array([[0,1,2,3,4,5,6,7,8,9]])</span><br><span class="line"></span><br><span class="line">a.shape</span><br><span class="line"># (1,10)</span><br><span class="line"></span><br><span class="line">b = np.squeeze(a)</span><br><span class="line"># array([0,1,2,3,4,5,6,7,8,9])</span><br><span class="line"></span><br><span class="line">b.shape</span><br><span class="line"># (10,)</span><br></pre></td></tr></table></figure><h4 id="dot"><a href="#dot" class="headerlink" title="dot()"></a>dot()</h4><p>向量点积    和     多维矩阵乘法</p><h4 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h4><p><strong>一维数组</strong></p><p>通过冒号分隔切片参数 start:stop:step 来进行切片操作：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b = a[<span class="number">2</span>:<span class="number">7</span>:<span class="number">2</span>]   <span class="comment"># 从索引 2 开始到索引 7 停止，间隔为 2</span></span><br></pre></td></tr></table></figure><p>冒号 : 的解释：如果只放置一个参数，如 [2]，将返回与该索引相对应的单个元素。如果为 [2:]，表示从该索引开始以后的所有项都将被提取。如果使用了两个参数，如 [2:7]，那么则提取两个索引(不包括停止索引)之间的项。</p><p><strong>注意1：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">7</span>:]</span><br><span class="line">array([<span class="number">8</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">7</span>]</span><br><span class="line"><span class="number">8</span></span><br></pre></td></tr></table></figure><p><strong>注意2：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(a[<span class="number">1</span>:<span class="number">3</span>])  <span class="comment">#从索引1开始，也就是第二个元素2，到索引3，不包括索引3</span></span><br><span class="line">[<span class="number">2</span> <span class="number">3</span>]</span><br></pre></td></tr></table></figure><p><strong>二维数组</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">a = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"></span><br><span class="line">[[<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>]</span><br><span class="line"> [<span class="number">3</span> <span class="number">4</span> <span class="number">5</span>]</span><br><span class="line"> [<span class="number">4</span> <span class="number">5</span> <span class="number">6</span>]]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">1</span>]</span><br><span class="line">array([<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">1</span>:]</span><br><span class="line">array([[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">      [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[:<span class="number">2</span>]</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">      [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">1</span>:<span class="number">2</span>]</span><br><span class="line">array([[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment">#进阶</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">1</span>,]</span><br><span class="line">array([<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">1</span>:,]</span><br><span class="line">array([[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>],</span><br><span class="line">      [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[:<span class="number">2</span>,]</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">      [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">1</span>:<span class="number">2</span>,]</span><br><span class="line">array([[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]])</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>总结：</p><hr><p>这是numpy的切片操作，一般结构如num[a:b,c:d]，分析时以逗号为分隔符，<br>逗号之前为要取的num行的下标范围(a到b-1)，逗号之后为要取的num列的下标范围(c到d-1)；<br>前面是行索引，后面是列索引。<br>如果是这种num[:b,c:d]，a的值未指定，那么a为最小值0；<br>如果是这种num[a:,c:d]，b的值未指定，那么b为最大值；c、d的情况同理可得。</p><hr><p>所以重点就是看逗号，没逗号，就是看行了，冒号呢，就看成一维数组的形式啦。那上面逗号后面没有树，也就是不对列操作咯。<br>当然也可以这样：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a[:<span class="number">2</span>:<span class="number">1</span>]</span><br><span class="line">array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">[<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]])</span><br></pre></td></tr></table></figure><p>首先没有逗号，那切片就是只看行了，这里的意思是，从0开始到2（2不算），间隔为1。</p><h3 id="结合matplotlib画图"><a href="#结合matplotlib画图" class="headerlink" title="结合matplotlib画图"></a>结合matplotlib画图</h3><p><code>%matplotlib inline</code> 可以在Ipython编译器里直接使用，功能是可以内嵌绘图，并且可以省略掉plt.show()这一步。</p><h4 id="pyplot库"><a href="#pyplot库" class="headerlink" title="pyplot库"></a>pyplot库</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><p>绘制直线</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">xpoints = np.array([<span class="number">0</span>, <span class="number">6</span>])</span><br><span class="line">ypoints = np.array([<span class="number">0</span>, <span class="number">100</span>])</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;TITLE&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;x - label&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;y - label&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.plot(xpoints, ypoints)</span><br><span class="line"></span><br><span class="line"><span class="comment"># plt.grid()        网格线</span></span><br><span class="line"><span class="comment"># plt.grid(axis=&#x27;x&#x27;)        设置y轴方向显示网格线</span></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>plt.plot()函数是绘制二维函数的最基本函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>plot(x, y)        <span class="comment"># 创建 y 中数据与 x 中对应值的二维线图，使用默认样式</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>plot(x, y, <span class="string">&#x27;bo&#x27;</span>)  <span class="comment"># 创建 y 中数据与 x 中对应值的二维线图，使用蓝色实心圈绘制</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>plot(y)           <span class="comment"># x 的值为 0..N-1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>plot(y, <span class="string">&#x27;r+&#x27;</span>)     <span class="comment"># 使用红色 + 号</span></span><br></pre></td></tr></table></figure><h4 id="绘制多图"><a href="#绘制多图" class="headerlink" title="绘制多图"></a>绘制多图</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#plot 1:</span></span><br><span class="line">x = np.array([<span class="number">0</span>, <span class="number">6</span>])</span><br><span class="line">y = np.array([<span class="number">0</span>, <span class="number">100</span>])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(x,y)</span><br><span class="line">plt.title(<span class="string">&quot;plot 1&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#plot 2:</span></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">y = np.array([<span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">16</span>])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(x,y)</span><br><span class="line">plt.title(<span class="string">&quot;plot 2&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#plot 3:</span></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">y = np.array([<span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">plt.plot(x,y)</span><br><span class="line">plt.title(<span class="string">&quot;plot 3&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#plot 4:</span></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">y = np.array([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>])</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">plt.plot(x,y)</span><br><span class="line">plt.title(<span class="string">&quot;plot 4&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.suptitle(<span class="string">&quot;Test&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://haoming2003.oss-cn-hangzhou.aliyuncs.com/%E4%B8%8B%E8%BD%BD.png" alt="plt"></p><p>注： <code>plt.subplot(2,2,1)</code> &lt;&#x3D;&gt; <code>plt.subplot(221)</code></p><h4 id="散点图"><a href="#散点图" class="headerlink" title="散点图"></a>散点图</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>])</span><br><span class="line">y = np.array([<span class="number">1</span>, <span class="number">4</span>, <span class="number">9</span>, <span class="number">16</span>, <span class="number">7</span>, <span class="number">11</span>, <span class="number">23</span>, <span class="number">18</span>])</span><br><span class="line">sizes = np.array([<span class="number">20</span>,<span class="number">50</span>,<span class="number">100</span>,<span class="number">200</span>,<span class="number">500</span>,<span class="number">1000</span>,<span class="number">60</span>,<span class="number">90</span>])</span><br><span class="line">plt.scatter(x, y, s=sizes)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="https://www.runoob.com/wp-content/uploads/2021/07/pl-scatter-5.png" alt="img"></p><h4 id="柱形图"><a href="#柱形图" class="headerlink" title="柱形图"></a>柱形图</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = np.array([<span class="string">&quot;num-1&quot;</span>, <span class="string">&quot;num-2&quot;</span>, <span class="string">&quot;num-3&quot;</span>, <span class="string">&quot;num-4&quot;</span>])</span><br><span class="line">y = np.array([<span class="number">12</span>, <span class="number">22</span>, <span class="number">6</span>, <span class="number">18</span>])</span><br><span class="line"></span><br><span class="line">plt.bar(x,y)</span><br><span class="line"><span class="comment"># plt.barh(x,y)水平柱状图</span></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h4 id="饼图"><a href="#饼图" class="headerlink" title="饼图"></a>饼图</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">y = np.array([<span class="number">35</span>, <span class="number">25</span>, <span class="number">25</span>, <span class="number">15</span>])</span><br><span class="line"></span><br><span class="line">plt.pie(y,</span><br><span class="line">        labels=[<span class="string">&#x27;A&#x27;</span>,<span class="string">&#x27;B&#x27;</span>,<span class="string">&#x27;C&#x27;</span>,<span class="string">&#x27;D&#x27;</span>], <span class="comment"># 设置饼图标签</span></span><br><span class="line">        colors=[<span class="string">&quot;#d5695d&quot;</span>, <span class="string">&quot;#5d8ca8&quot;</span>, <span class="string">&quot;#65a479&quot;</span>, <span class="string">&quot;#a564c9&quot;</span>], <span class="comment"># 设置饼图颜色</span></span><br><span class="line">       )</span><br><span class="line">plt.title(<span class="string">&quot;Pie Test&quot;</span>) <span class="comment"># 设置标题</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><h4 id="三维图"><a href="#三维图" class="headerlink" title="三维图"></a>三维图</h4><p>最基本的三维图是线图与<a href="https://so.csdn.net/so/search?q=%E6%95%A3%E7%82%B9%E5%9B%BE&spm=1001.2101.3001.7020">散点图</a>，可以用<code>ax.plot3D</code>和<code>ax.scatter3D</code>函数来创建</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#绘制三角螺旋线</span></span><br><span class="line"><span class="keyword">from</span> mpl_toolkits <span class="keyword">import</span> mplot3d</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">ax = plt.axes(projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#三维线的数据</span></span><br><span class="line">zline = np.linspace(<span class="number">0</span>, <span class="number">15</span>, <span class="number">1000</span>)</span><br><span class="line">xline = np.sin(zline)</span><br><span class="line">yline = np.cos(zline)</span><br><span class="line">ax.plot3D(xline, yline, zline, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 三维散点的数据</span></span><br><span class="line">zdata = <span class="number">15</span> * np.random.random(<span class="number">100</span>)</span><br><span class="line">xdata = np.sin(zdata) + <span class="number">0.1</span> * np.random.randn(<span class="number">100</span>)</span><br><span class="line">ydata = np.cos(zdata) + <span class="number">0.1</span> * np.random.randn(<span class="number">100</span>)</span><br><span class="line">ax.scatter3D(xdata, ydata, zdata, c=zdata, cmap=<span class="string">&#x27;Greens&#x27;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://haoming2003.oss-cn-hangzhou.aliyuncs.com/image-20230104104737680.png" alt="image-20230104104737680"></p><h4 id="热图"><a href="#热图" class="headerlink" title="热图"></a>热图</h4><p>imshow()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">X = [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>]]</span><br><span class="line">plt.imshow(X)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="C:\Users\xhm\AppData\Roaming\Typora\typora-user-images\image-20230104164258648.png" alt="image-20230104164258648"></p><p>博客：<a href="https://blog.csdn.net/qq_21763381/article/details/100169288">https://blog.csdn.net/qq_21763381/article/details/100169288</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> python三剑客 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>csapp_machine_code_control</title>
      <link href="/2022/12/29/csapp-machine-code-control/"/>
      <url>/2022/12/29/csapp-machine-code-control/</url>
      
        <content type="html"><![CDATA[<h3 id="control"><a href="#control" class="headerlink" title="control"></a>control</h3><h2 id="处理器状态-x86-64-Partial"><a href="#处理器状态-x86-64-Partial" class="headerlink" title="处理器状态 (x86-64, Partial)"></a>处理器状态 (x86-64, Partial)</h2><p><img src="https://img-blog.csdnimg.cn/20190724111040785.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5kZXpodXRp,size_16,color_FFFFFF,t_70" alt="img"></p><p>图上的CF,ZF,SF,OF就是微机学过的状态位，其中各自代表的意思如下</p><p><img src="https://img-blog.csdnimg.cn/20190724111626651.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5kZXpodXRp,size_16,color_FFFFFF,t_70" alt="img"></p><p><img src="https://img-blog.csdnimg.cn/20190724112028471.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5kZXpodXRp,size_16,color_FFFFFF,t_70" alt="img"></p><p><img src="https://img-blog.csdnimg.cn/20190724112037452.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5kZXpodXRp,size_16,color_FFFFFF,t_70" alt="img"></p><p><img src="https://img-blog.csdnimg.cn/2019072411205365.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5kZXpodXRp,size_16,color_FFFFFF,t_70" alt="img"></p><p><img src="https://img-blog.csdnimg.cn/20190724112113371.png" alt="img"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>machine_code（1）</title>
      <link href="/2022/12/27/csapp-machine-code-md/"/>
      <url>/2022/12/27/csapp-machine-code-md/</url>
      
        <content type="html"><![CDATA[<h4 id="处理器模型发展"><a href="#处理器模型发展" class="headerlink" title="处理器模型发展"></a>处理器模型发展</h4><p><a href="https://hansimov.gitbook.io/csapp/part1/ch03-machine-level-representing-of-programs/3.1-a-historial-perspective">https://hansimov.gitbook.io/csapp/part1/ch03-machine-level-representing-of-programs/3.1-a-historial-perspective</a></p><h4 id="摩尔定律"><a href="#摩尔定律" class="headerlink" title="摩尔定律"></a>摩尔定律</h4><h4 id="芯片构造"><a href="#芯片构造" class="headerlink" title="芯片构造"></a>芯片构造</h4><p><img src="https://haoming2003.oss-cn-hangzhou.aliyuncs.com/image-20221227205856257.png" alt="image-20221227205856257"></p><p>标准桌面型号有四个核心，服务器级别的机器有八个核心（上图）</p><p>芯片周围连接外围设备的接口：</p><ul><li>DDR是连接到主存的方式，即所谓的DRAM（Dynamic动态 RAM）</li><li>PCI是一种同步的独立于处理器的32位或64位局部总线，主要用于连接显示卡、网卡、声卡</li><li>SATA是与不同类型盘连接</li><li>USB接口与USB设备连接</li><li>ethernet网络连接</li></ul><p>集成到芯片上的不止是处理器还有很多逻辑单元</p><h4 id="处理器架构"><a href="#处理器架构" class="headerlink" title="处理器架构"></a>处理器架构</h4><table><thead><tr><th><strong>架构</strong></th><th><strong>特点</strong></th><th><strong>代表性的厂商</strong></th><th><strong>运营机构</strong></th></tr></thead><tbody><tr><td><strong>X86</strong></td><td><strong>性能高，速度快，兼容性好</strong></td><td><strong>英特尔，AMD</strong></td><td><strong>英特尔</strong></td></tr><tr><td><strong>ARM</strong></td><td><strong>成本低，低功耗</strong></td><td><strong>苹果，谷歌，IBM，华为</strong></td><td><strong>英国ARM公司</strong></td></tr><tr><td><strong>RISC-V</strong></td><td><strong>模块化，极简，可拓展</strong></td><td><strong>三星，英伟达，西部数据</strong></td><td><strong>RISC-V基金会</strong></td></tr><tr><td><strong>MIPS</strong></td><td><strong>简洁，优化方便，高拓展性</strong></td><td><strong>龙芯</strong></td><td><strong>MIPS科技公司</strong></td></tr></tbody></table><p><strong>X86在PC上占据大部分份额，ARM在手机处理器上占据绝对份额</strong></p><h4 id="c代码运行的过程"><a href="#c代码运行的过程" class="headerlink" title="c代码运行的过程"></a>c代码运行的过程</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gcc -Og -S sum.c</span><br><span class="line"><span class="comment">// 将c代码转换为assembly代码</span></span><br></pre></td></tr></table></figure><p>-s为-stop停在把c转化为汇编的时刻</p><p>-Og是我希望编译器做什么样的优化的规范，这样才能读懂</p><p>具体过程：<a href="https://www.cnblogs.com/carpenterlee/p/5994681.html">https://www.cnblogs.com/carpenterlee/p/5994681.html</a></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">objdump -d sum &gt; sum.d</span><br></pre></td></tr></table></figure><p>反汇编，sum.d的内容</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">a.out:     file format elf64-x86<span class="number">-64</span></span><br><span class="line">     </span><br><span class="line">Disassembly of section .init:</span><br><span class="line"></span><br><span class="line"><span class="number">0000000000001000</span> &lt;_init&gt;:</span><br><span class="line">    <span class="number">1000</span>:   f3 <span class="number">0f</span> <span class="number">1</span>e fa             endbr64</span><br><span class="line">    <span class="number">1004</span>:   <span class="number">48</span> <span class="number">83</span> ec <span class="number">08</span>             sub    $<span class="number">0x8</span>,%rsp</span><br><span class="line">    <span class="number">1008</span>:   <span class="number">48</span> <span class="number">8b</span> <span class="number">05</span> d9 <span class="number">2f</span> <span class="number">00</span> <span class="number">00</span>    mov    <span class="number">0x2fd9</span>(%rip),%rax        # <span class="number">3f</span>e8 &lt;__gmon_start__&gt;</span><br><span class="line">    <span class="number">100f</span>:   <span class="number">48</span> <span class="number">85</span> c0                test   %rax,%rax</span><br><span class="line">    <span class="number">1012</span>:   <span class="number">74</span> <span class="number">02</span>                   je     <span class="number">1016</span> &lt;_init+<span class="number">0x16</span>&gt;</span><br><span class="line">    <span class="number">1014</span>:   ff d0                   callq  *%rax</span><br><span class="line">    <span class="number">1016</span>:   <span class="number">48</span> <span class="number">83</span> c4 <span class="number">08</span>             add    $<span class="number">0x8</span>,%rsp</span><br><span class="line">    <span class="number">101</span>a:   c3                      retq</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure><p><strong>反汇编程序无法访问源代码，甚至无法访问汇编代码，它只是通过实际目标代码文件中的字节来辨别出来的</strong></p><p>或者使用GDB</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; gdb</span><br><span class="line">...</span><br><span class="line">(gdb)</span><br><span class="line">(gdb) disassemble bitXor</span><br><span class="line">Dump of assembler code <span class="keyword">for</span> function bitXor:</span><br><span class="line">   <span class="number">0x0000000000001149</span> &lt;+<span class="number">0</span>&gt;:     endbr64</span><br><span class="line">   <span class="number">0x000000000000114d</span> &lt;+<span class="number">4</span>&gt;:     push   %rbp</span><br><span class="line">   <span class="number">0x000000000000114e</span> &lt;+<span class="number">5</span>&gt;:     mov    %rsp,%rbp</span><br><span class="line">   <span class="number">0x0000000000001151</span> &lt;+<span class="number">8</span>&gt;:     mov    %edi,<span class="number">-0x4</span>(%rbp)</span><br><span class="line">   <span class="number">0x0000000000001154</span> &lt;+<span class="number">11</span>&gt;:    mov    %esi,<span class="number">-0x8</span>(%rbp)</span><br><span class="line">   <span class="number">0x0000000000001157</span> &lt;+<span class="number">14</span>&gt;:    mov    <span class="number">-0x4</span>(%rbp),%eax</span><br><span class="line">   <span class="number">0x000000000000115a</span> &lt;+<span class="number">17</span>&gt;:    xor    <span class="number">-0x8</span>(%rbp),%eax</span><br><span class="line">   <span class="number">0x000000000000115d</span> &lt;+<span class="number">20</span>&gt;:    pop    %rbp</span><br><span class="line">   <span class="number">0x000000000000115e</span> &lt;+<span class="number">21</span>&gt;:    retq</span><br><span class="line">End of assembler dump.</span><br></pre></td></tr></table></figure><p><strong>此方法前面显示的是16进制地址而非像objdum那样的字节级编码</strong></p><h4 id="Assembly-Characteristics-Data-Types-汇编语言特性"><a href="#Assembly-Characteristics-Data-Types-汇编语言特性" class="headerlink" title="Assembly Characteristics: Data Types 汇编语言特性"></a>Assembly Characteristics: Data Types 汇编语言特性</h4><ul><li>“Integer” data type of 1,2,4,or 8 bytes，不区分unsigned和signed</li><li>floating point 有4,8,10,bytes</li><li>没有数组以及一些数据结构，只是内存中连续存储的单元</li></ul><h4 id="x86-64-Integer-Registers"><a href="#x86-64-Integer-Registers" class="headerlink" title="x86-64 Integer Registers"></a>x86-64 Integer Registers</h4><p>有16个寄存器</p><p><img src="https://img-blog.csdnimg.cn/20190723112517340.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5kZXpodXRp,size_16,color_FFFFFF,t_70" alt="img"></p><p>注意到 %r代表62位操作 %e代表了32位的操作，%e版本只是%r实体的低32位。</p><p><strong>%rsp寄存器存的是栈指针，它能告诉你程序执行到哪儿了</strong></p><h4 id="移动数据"><a href="#移动数据" class="headerlink" title="移动数据"></a>移动数据</h4><h5 id="格式"><a href="#格式" class="headerlink" title="格式"></a>格式</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">moveq Source Dest</span><br></pre></td></tr></table></figure><h5 id="操作数类型"><a href="#操作数类型" class="headerlink" title="操作数类型"></a>操作数类型</h5><p><img src="https://img-blog.csdnimg.cn/20190723113325695.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5kZXpodXRp,size_16,color_FFFFFF,t_70" alt="img"></p><h5 id="操作数组合"><a href="#操作数组合" class="headerlink" title="操作数组合"></a>操作数组合</h5><p><img src="https://img-blog.csdnimg.cn/20190723113456800.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5kZXpodXRp,size_16,color_FFFFFF,t_70" alt="img"></p><h4 id="理解Swap-函数"><a href="#理解Swap-函数" class="headerlink" title="理解Swap()函数"></a>理解Swap()函数</h4><p><img src="https://img-blog.csdnimg.cn/20190723125635539.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5kZXpodXRp,size_16,color_FFFFFF,t_70" alt="img"></p><p>使用x86-64的时候，函数参数总是出现在某些特定的寄存器中，**%rdi将是第一个参数寄存器，%rsi将是第二个参数寄存器**。最多可以有6个</p><h4 id="完整的内存地址模式"><a href="#完整的内存地址模式" class="headerlink" title="完整的内存地址模式"></a>完整的内存地址模式</h4><p><img src="https://img-blog.csdnimg.cn/20190723125841927.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5kZXpodXRp,size_16,color_FFFFFF,t_70" alt="img"></p><p>下面是内存完整模式的一个例子</p><p><img src="https://img-blog.csdnimg.cn/20190723130008460.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5kZXpodXRp,size_16,color_FFFFFF,t_70" alt="img"></p><h4 id="地址计算"><a href="#地址计算" class="headerlink" title="地址计算"></a>地址计算</h4><p><img src="https://img-blog.csdnimg.cn/20190723131714576.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5kZXpodXRp,size_16,color_FFFFFF,t_70" alt="img"></p><p><img src="C:\Users\xhm\AppData\Roaming\Typora\typora-user-images\image-20221229121353910.png" alt="image-20221229121353910"></p><p><img src="C:\Users\xhm\AppData\Roaming\Typora\typora-user-images\image-20221229121547636.png" alt="image-20221229121547636"></p><p><img src="https://img-blog.csdnimg.cn/20190723131745599.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoZW5kZXpodXRp,size_16,color_FFFFFF,t_70" alt="img"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>csapp_CouseOverview</title>
      <link href="/2022/12/23/csapp-CouseOverview-md/"/>
      <url>/2022/12/23/csapp-CouseOverview-md/</url>
      
        <content type="html"><![CDATA[<hr><hr><p>写在前面; 今天是12.23，经历了新冠的抗争后开始学习csapp，教材课程及练习都使用CMU 15-213。希望能在这个寒假学习完毕</p><hr><h3 id="Ints-are-not-Interagers-Float-are-not-Reals"><a href="#Ints-are-not-Interagers-Float-are-not-Reals" class="headerlink" title="Ints are not Interagers, Float are not Reals"></a>Ints are not Interagers, Float are not Reals</h3><p>Example 1:</p><ul><li>Float’s : Yes!</li><li>Int’s:<ul><li>40000 * 40000 -&gt; 1600000000</li><li>50000 * 50000 -&gt; ??</li></ul></li></ul><p>Example 2:  Is (x + y) + z &#x3D; x + (y  + z )   ?</p><ul><li>Int’s:: Yes!</li><li>Float’s : Not Sure!!</li></ul><p>Float will throw the more number!</p><h3 id="Memory-Referencing-Bug-Example"><a href="#Memory-Referencing-Bug-Example" class="headerlink" title="Memory Referencing Bug Example"></a>Memory Referencing Bug Example</h3><p><img src="https://haoming2003.oss-cn-hangzhou.aliyuncs.com/202212231500118.png" alt="image-20221223150035984"></p><p><img src="https://haoming2003.oss-cn-hangzhou.aliyuncs.com/202212231513136.png" alt="image-20221223151356105"></p><p><strong>For sure, this is influenced by your gcc version and IDE</strong>.</p>]]></content>
      
      
      
        <tags>
            
            <tag> csapp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch深度学习总结</title>
      <link href="/2022/11/09/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93-md/"/>
      <url>/2022/11/09/pytorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93-md/</url>
      
        <content type="html"><![CDATA[<h2 id="深度学习流程"><a href="#深度学习流程" class="headerlink" title="深度学习流程"></a>深度学习流程</h2><h3 id="流程简述"><a href="#流程简述" class="headerlink" title="流程简述"></a>流程简述</h3><pre class="mermaid">graph TD a[Build the dataset]-->b[preprocessing] b[preprocessing]-->c[training and validation] c-->d[Parameter tuning && optimization]</pre><h3 id="构建数据集："><a href="#构建数据集：" class="headerlink" title="构建数据集："></a>构建数据集：</h3><ol><li>流程</li></ol><p>first step: 收集数据：去大量抽样调查收集，爬虫（<a href="https://github.com/MrS0m30n3/youtube-dl-gui">youtube爬虫工具</a>），众包（<del>花钱找工具人</del>）等等</p><p>second: 数据格式整理</p><p>third: 导入代码进行处理</p><ol start="2"><li><p>code</p><p>一般处理csv或者json等格式的文本格式文件，下为举例</p><p>sklearn</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">data = pd.read_json(<span class="string">&#x27;data.json&#x27;</span>)</span><br><span class="line"><span class="comment"># data = pd.read_csv(&#x27;data.csv&#x27;)</span></span><br></pre></td></tr></table></figure><p>pytorch</p><p>​pytorch的项目预处理的时候可以用pandas、json等库处理，之后生成新的文件在构建模型前构造DataSet和DataLoader时直接读取数据集来load</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train_dataset = MyDataset(csv_file=<span class="string">&#x27;../data/data.csv&#x27;</span>,</span><br><span class="line">root_dir=<span class="string">&#x27;../data&#x27;</span>,</span><br><span class="line">transform=torchvision.transforms.ToTensor())</span><br></pre></td></tr></table></figure></li></ol><h3 id="数据集划分："><a href="#数据集划分：" class="headerlink" title="数据集划分："></a>数据集划分：</h3><ol><li>基本知识</li></ol><ul><li><p>训练集（Train Set）: 模型用于训练和调整模型参数</p></li><li><p>验证集（Validation Set）: 用来验证模型精度和调整</p></li><li><p>测试集（Test Set）: 验证模型的泛化能力</p></li></ul><blockquote><p>训练集和验证集有时候是从同一数据集中分开的，但是在划分验证集时需要注意验证集的分布需和测试集尽量保持一致，保证其泛化性</p></blockquote><p>几种划分方式：</p><ul><li><p>留出法（Hold-Out）：直接将训练集划分为新的训练集和验证集。优点简单。缺点只得到了一份验证集，有可能导致模型在验证集上过拟合，适用于数据量比较大点的情况。</p></li><li><p>交叉验证法（Cross Validation,CV）：将训练集划分成K份，将其中的K-1份作为训练集，剩余的1份作为验证集，循环K训练。这种划分方式是所有的训练集都是验证集，最终模型验证精度是K份平均得到。这种方式的优点是验证集精度比较可靠，训练K次可以得到K个有多样性差异的模型；CV验证的缺点是需要训练K次，不适合数据量很大的情况。</p></li><li><p>自助采样法（BootStrap）：通过有放回的采样方式得到新的训练集和验证集，每次的训练集和验证集都是有区别的。这种划分方式一般适用于数据量较小的情况。</p></li></ul><ol start="2"><li><p>code: </p><p>sklearn</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"></span><br><span class="line">os.chdir(<span class="string">&#x27;breast_cancer_data&#x27;</span>)</span><br><span class="line">data = pd.read_csv(<span class="string">r&#x27;data.csv&#x27;</span>)</span><br><span class="line">data.drop(<span class="string">&#x27;Unnamed: 32&#x27;</span>,inplace = <span class="literal">True</span>,axis = <span class="number">1</span>)</span><br><span class="line">data.drop(<span class="string">&#x27;id&#x27;</span>,inplace = <span class="literal">True</span>,axis=<span class="number">1</span>)</span><br><span class="line">y = data[<span class="string">&#x27;diagnosis&#x27;</span>]</span><br><span class="line">x = data.drop(<span class="string">&#x27;diagnosis&#x27;</span>,axis = <span class="number">1</span>)</span><br><span class="line">model = RandomForestClassifier()</span><br></pre></td></tr></table></figure><p>留出法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">14x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="number">0.33</span>, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure><p>k折交叉验证：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line">kf = KFold(n_splits = <span class="number">10</span>)</span><br><span class="line">accuracy = []</span><br><span class="line"><span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> kf.split(x):</span><br><span class="line">     x_train, x_test = x.loc[train_index],x.loc[test_index]</span><br><span class="line">     y_train, y_test = y.loc[train_index],y.loc[test_index]</span><br><span class="line">     model.fit(x_train, y_train)</span><br><span class="line">     prediction = model.predict(x_test)</span><br><span class="line">     acc=metrics.accuracy_score(predocton, y_test)</span><br><span class="line">     accuracy,append(acc)</span><br><span class="line"><span class="built_in">print</span>(accuracy)</span><br><span class="line"><span class="built_in">print</span>(np.average(accuracy))</span><br></pre></td></tr></table></figure><p>pytorch:</p><p><strong>torch.utils.data.Subset</strong>或者<strong>random_split</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])</span><br></pre></td></tr></table></figure><p>或者自定义分类数据集</p><p>eg: 文本分类中可以根据文本数字先进行排序然后按照顺序每10个前9个放入训练集后1个放入测试集(若为9:1)，然后训练时再进行shuffle，这样保证了分布均匀的问题</p></li></ol><h3 id="模型训练和验证"><a href="#模型训练和验证" class="headerlink" title="模型训练和验证"></a>模型训练和验证</h3><ol><li><p>仔细检查数据：</p><p>花时间去检查数据是一件比较重要的工作。因为数据中往往可能存在异常值，而且了解它们的分布可以有利于我们找到一个更好的模型。同时也可以对数据进行一开始的手动调整。</p></li><li><p>搭建模型并开始训练验证</p><p>评估框架提示</p><ul><li>固定随机种子：始终使用固定的随机种子来确保两次运行代码时，您将获得相同的结果。</li><li>简化：去除不必要的一些操作</li><li>验证损失：验证损失是否从正确的损失值开始</li><li>设定一个好的初始化</li><li>人类基线：监控除损失之外的指标，这些指标是人类可以解释和检查的（例如准确性）。尽可能评估自己（人类）的准确性并与之进行比较。</li><li>可视化预测动态。训练过程中可视化固定测试批次上的模型预测对模型调整有很大帮助。</li></ul></li><li><p>过度拟合</p></li></ol><p>找到一个好的模型的方法有两个阶段：首先获得一个足够大的模型以使其可以过度拟合（即专注于训练损失），然后适当地对其进行正则化（放弃一些训练损失以提高验证损失）。</p><p>此阶段的一些提示和技巧：</p><ul><li>选择模型：为了减少训练损失，您需要为数据选择合适的体系结构。</li><li>Adam是安全的。在设定基准的早期阶段，我喜欢以3e-4的学习率使用Adam 。以我的经验，亚当更宽容超参数，包括不良的学习速度。对于ConvNets，调整良好的SGD几乎总是比Adam稍胜一筹，但是最佳学习率区域要狭窄得多且针对特定问题。</li><li>一次只使一个复杂化。如果您有多个信号要插入您的分类器，我建议您将它们一个接一个地插入，并每次确保获得预期的性能提升。</li><li>不要相信学习率衰减的默认值。如果您要重新使用其他领域的代码，请务必小心学习率。</li></ul><p><strong>4. 正则化</strong></p><p>此阶段的一些提示和技巧：</p><ul><li>获取更多数据</li><li>数据扩充</li><li>创意增强：如果半假数据没有做到这一点，伪造数据也可能会有所作为。人们正在寻找扩展数据集的创新方法。例如，领域随机化，模拟的使用，巧妙的混合，例如将（潜在模拟的）数据插入场景，甚至GAN。</li><li>使用预训练网络</li><li>坚持监督学习</li><li>减小输入维数</li><li>减小模型尺寸</li><li>减小批量大小</li><li>Dropout</li><li>提早停止训练。根据您测得的验证损失提前停止训练，以在模型快要过拟合的时候捕获模型。</li><li>尝试更大的模型。大型模型大多数最终会过拟合，但是它们的“早期停止”性能通常会比小型模型好得多。</li></ul><p><strong>5. 微调</strong></p><p>此阶段的一些提示和技巧：</p><ul><li>随机网格搜索</li><li>超参数优化</li></ul><p><strong>6. 进一步提高精确率</strong></p><ul><li>模型集成</li></ul><p>代码参考搭建过的一些项目</p>]]></content>
      
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>github fork仓库向主工程提交代码</title>
      <link href="/2022/09/22/github-fork%E4%BB%93%E5%BA%93%E5%90%91%E4%B8%BB%E5%B7%A5%E7%A8%8B%E6%8F%90%E4%BA%A4%E4%BB%A3%E7%A0%81/"/>
      <url>/2022/09/22/github-fork%E4%BB%93%E5%BA%93%E5%90%91%E4%B8%BB%E5%B7%A5%E7%A8%8B%E6%8F%90%E4%BA%A4%E4%BB%A3%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<h2 id="1-fork并关联本地"><a href="#1-fork并关联本地" class="headerlink" title="1. fork并关联本地"></a>1. fork并关联本地</h2><p>进入我的主页，找到这个仓库</p><p><img src="https://haoming2003.oss-cn-hangzhou.aliyuncs.com/202209220208551.png" alt="image-20220922020848487"></p><p>点击右上角的fork，然后你的主页里就多了一个同样的仓库了，相当于做了一个镜像开了个分支</p><p>然后在本地合适位置（最好别带中文）建立一个同名文件夹（名字不影响，但是为了一致嘛），然后在文件夹中打开git bash(path配置好了的话，powershell也可以)，然后按照如下流程输入（有梯子的话最好打开梯子）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 克隆fork后仓库到本地,yourname为你的github名</span></span><br><span class="line">git <span class="built_in">clone</span> （fork后的url）</span><br></pre></td></tr></table></figure><p>然后你的文件夹下就会出现本项目已有所有文件，然后你就可以在本地仓库的对应文件夹（你的名字）添加你的学习文件了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># add到本地暂存区, .是add所有新文件的意思</span></span><br><span class="line">git add .</span><br><span class="line"></span><br><span class="line"><span class="comment"># commit到本地仓库</span></span><br><span class="line">git commit -m <span class="string">&quot;first_commit&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 关联到你的远程仓库</span></span><br><span class="line">git remote add origin your_url</span><br><span class="line"></span><br><span class="line"><span class="comment"># push到你的远程仓库</span></span><br><span class="line">git push -u origin main</span><br></pre></td></tr></table></figure><p><img src="https://haoming2003.oss-cn-hangzhou.aliyuncs.com/202209220214651.webp" alt="img"></p><p>然后你fork的仓库会出现你的新增文件</p><h2 id="2-关联主工程"><a href="#2-关联主工程" class="headerlink" title="2.关联主工程"></a>2.关联主工程</h2><p>关联主工程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git remote add okex(自定义分支名) (主工程的git url)</span><br><span class="line"><span class="comment"># 查看关联情况</span></span><br><span class="line">git remote -v</span><br></pre></td></tr></table></figure><p><img src="https://haoming2003.oss-cn-hangzhou.aliyuncs.com/202209220224884.png" alt="在这里插入图片描述"></p><p>拉取主工程各分支信息到本地：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git fetch okex(自定义分支名)</span><br></pre></td></tr></table></figure><p><img src="https://haoming2003.oss-cn-hangzhou.aliyuncs.com/202209220224876.png" alt="在这里插入图片描述"></p><p>在本地切换到主分支的某分支（比如develop）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout develop</span><br></pre></td></tr></table></figure><p>在此分支的基础上创建一个自己的分支：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b michael.w</span><br></pre></td></tr></table></figure><p>开始做代码修改。</p><p>代码commit后向自己的repo push代码：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push</span><br></pre></td></tr></table></figure><p>这里可能报错，请根据报错内容自行纠正</p><p><img src="https://haoming2003.oss-cn-hangzhou.aliyuncs.com/202209220224883.png" alt="在这里插入图片描述"></p><ol><li>从自己的repo中向主工程发起request pull：<br><img src="https://haoming2003.oss-cn-hangzhou.aliyuncs.com/202209220224879.png" alt="在这里插入图片描述"><br>选择要提交的目标分支：<br><img src="https://haoming2003.oss-cn-hangzhou.aliyuncs.com/202209220224980.png" alt="在这里插入图片描述"></li></ol><h3 id="如何将主分支的更新进度同步到我的repo中"><a href="#如何将主分支的更新进度同步到我的repo中" class="headerlink" title="如何将主分支的更新进度同步到我的repo中"></a>如何将主分支的更新进度同步到我的repo中</h3><p>假设主工程的开发分支时main</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">切到本地的main分支</span></span><br><span class="line">git checkout main</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将okex的的main分支拉取下来并与本地现在所处分支合并</span></span><br><span class="line">git pull okex main</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">推到我的repo</span></span><br><span class="line">git push</span><br></pre></td></tr></table></figure><hr><blockquote><p><strong>本文参考了<a href="https://blog.csdn.net/michael_wgy_/article/details/104589800">wgy的博客</a>，侵删</strong></p></blockquote><blockquote><p><strong>由于github默认分支改变，以上master记得改为main</strong></p></blockquote><hr>]]></content>
      
      
      
        <tags>
            
            <tag> github代码提交 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>github+hexo+butterfly搭建博客</title>
      <link href="/2022/09/21/github-hexo-butterfly%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/"/>
      <url>/2022/09/21/github-hexo-butterfly%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<hr><p>突然想到搭建一个博客玩，其实之前也在csdn上发过一点，但是没坚持下来，太失败了</p><p>希望这次可以坚持下来，下面记录一下搭建过程</p><hr><h3 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h3><ol><li><p>github账号</p></li><li><p>nodejs, npm（版本别太低）</p></li></ol><p>上网搜具体的安装教程，肯定比我写得好</p><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><h4 id="创建username-github-io的项目"><a href="#创建username-github-io的项目" class="headerlink" title="创建username.github.io的项目"></a>创建<strong>username.github.io</strong>的项目</h4><p>（记住<strong>username</strong>跟你<strong>github</strong>名称同名）</p><p>在合适的地方新建一个文件夹，用来存放自己的博客文件，我的放在<code>D:\blog</code>下</p><p><strong>在该目录下</strong></p><h4 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装<strong>Hexo</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i hexo-cli -g</span><br></pre></td></tr></table></figure><p>可能会有几个报错，忽略</p><p>安装完后用 <strong>hexo -v</strong> 验证是否安装成功</p><h4 id="初始化并生成网页"><a href="#初始化并生成网页" class="headerlink" title="初始化并生成网页"></a><strong>初始化</strong>并生成网页</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hexo init</span><br><span class="line"></span><br><span class="line">npm install <span class="comment"># 安装必备组件</span></span><br><span class="line"></span><br><span class="line">hexo g <span class="comment"># 生成静态网页</span></span><br><span class="line"></span><br><span class="line">hexo s <span class="comment"># 打开本地服务器,打开http://localhost:4000/,就有效果了</span></span><br></pre></td></tr></table></figure><p><strong>ctrl</strong> + <strong>c</strong>关闭本地服务器</p><h4 id="连接github和本地"><a href="#连接github和本地" class="headerlink" title="连接github和本地"></a>连接github和本地</h4><p>在根目录下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name <span class="string">&quot;HaomingX&quot;</span></span><br><span class="line">git config --global user.email <span class="string">&quot;978545377@qq.com&quot;</span></span><br><span class="line"><span class="comment"># 根据你注册github的信息替换成你自己的</span></span><br></pre></td></tr></table></figure><p>生成密钥SSH key</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -C <span class="string">&quot;978545377@qq.com&quot;</span></span><br></pre></td></tr></table></figure><p>打开<a href="http://github.com/">github</a>，点击<code>settings</code>，再点击<code>SSH and GPG keys</code>，新建一个SSH，名字任意</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> ~/.ssh/id_rsa.pub</span><br></pre></td></tr></table></figure><p>复制到ssh密匙框中，保存</p><p>输入<code>ssh -T git@github.com</code>，如果说了Hi 用户名!,你就成功了</p><p>打开博客根目录下的<code>_config.yml</code>文件，这是博客的配置文件</p><p>修改最后一行的配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  <span class="built_in">type</span>: git</span><br><span class="line">  repository: https://github.com/HaomingX/HaomingX.github.io</span><br><span class="line">  branch: main</span><br></pre></td></tr></table></figure><h4 id="写文章"><a href="#写文章" class="headerlink" title="写文章"></a>写文章</h4><p>根目录下安装扩展</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm i hexo-deployer-git</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建文章</span></span><br><span class="line">hexo new post <span class="string">&quot;文章名&quot;</span></span><br></pre></td></tr></table></figure><p>打开<code>D:\blog\source\_posts</code>的目录，可以发现下面多了一个<code>.md</code>文件</p><p>编写完后</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo s</span><br><span class="line"></span><br><span class="line">hexo d <span class="comment"># 上传到github</span></span><br></pre></td></tr></table></figure><p>打开你的<a href="https://github.io/">github.io</a>主页就能看到发布的文章</p><h3 id="butterfly美化"><a href="#butterfly美化" class="headerlink" title="butterfly美化"></a>butterfly美化</h3><p><a href="https://tzy1997.com/articles/hexo1603/">可以跟这个博主的教程走，写得很好</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> 博客搭建 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
